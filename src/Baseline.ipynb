{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.utils import weight_norm\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import pdb\n",
    "from logger import Logger\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "num_channels = 3\n",
    "num_classes = 1\n",
    "num_epochs = 300\n",
    "image_size = 32\n",
    "batch_size = 64\n",
    "epsilon = 1e-8 # used to avoid NAN loss\n",
    "logger = Logger('./logs')\n",
    "\n",
    "# Initialize parameters\n",
    "lr = 1e-5\n",
    "b1 = 0.5 # adam: decay of first order momentum of gradient\n",
    "b2 = 0.999 # adam: decay of first order momentum of gradient\n",
    "\n",
    "model_path ='./baseline.tar'\n",
    "image_dir = 'baseline_images'\n",
    "\n",
    "os.makedirs(image_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "class TCGADataset(Dataset):\n",
    "    def __init__(self, image_size, split):\n",
    "        self.split = split\n",
    "        self.tcga_dataset = self._create_dataset(image_size, split)\n",
    "        self.patches, self.labels = self.tcga_dataset\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "        ])\n",
    "        \n",
    "    def _create_dataset(self, image_size, split):\n",
    "        data_dir = '../dataset/patch_data'\n",
    "        if self.split == 'train':\n",
    "            data_dir = os.path.join(data_dir, 'train')\n",
    "        else:\n",
    "            data_dir = os.path.join(data_dir, 'dev')\n",
    "        \n",
    "        all_files = os.listdir(data_dir)\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        # Iterate over all files\n",
    "        for file in all_files:\n",
    "            if '.npz' not in file:\n",
    "                continue\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            data = np.load(file_path)\n",
    "            X = data['arr_0']\n",
    "            y = data['arr_1']\n",
    "            images.append(X)\n",
    "            labels.append(y)                \n",
    "            \n",
    "        images = np.concatenate(images)\n",
    "        labels = np.concatenate(labels) \n",
    "        \n",
    "        # Print data statistics\n",
    "        print(\"Total number of patches : \",labels.shape[0])\n",
    "        c = 0\n",
    "        nc = 0\n",
    "        for l in labels:\n",
    "            if l:\n",
    "                c+=1\n",
    "            else:\n",
    "                nc+=1\n",
    "        print(\"Cancerous patches : \",c )\n",
    "        print(\"Non cancerous patches : \",nc )\n",
    "            \n",
    "        return images, labels\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.patches[idx], self.labels[idx]\n",
    "        return self.transform(Image.fromarray(data)), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataloaders\n",
    "def get_loader(image_size, batch_size):\n",
    "    num_workers = 2\n",
    "    tcga_train = TCGADataset(image_size=image_size, split='train')\n",
    "#     tcga_test = TCGADataset(image_size=image_size, split='test')\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=tcga_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "#     test_loader = DataLoader(\n",
    "#         dataset=tcga_test,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=True\n",
    "#         #num_workers=num_workers\n",
    "#     )\n",
    "\n",
    "    return train_loader#, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.zero_()\n",
    "        \n",
    "        \n",
    "def initializer(m):\n",
    "    # Run xavier on all weights and zero all biases\n",
    "    if hasattr(m, 'weight'):\n",
    "        if m.weight.ndimension() > 1:\n",
    "            xavier_uniform_(m.weight.data)\n",
    "\n",
    "    if hasattr(m, 'bias') and m.bias is not None:\n",
    "        m.bias.data.zero_() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "          \n",
    "        dropout_rate = 0.5\n",
    "        filter1 = 96\n",
    "        filter2 = 192\n",
    "        \n",
    "        # Conv operations\n",
    "        # CNNBlock 1\n",
    "        self.wn_conv1 = nn.Sequential(\n",
    "            weight_norm(nn.Conv2d(in_channels=num_channels, out_channels=filter1, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter1, out_channels=filter1, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter1, out_channels=filter1, kernel_size=3, stride=2, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout2d(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # CNNBlock 2\n",
    "        self.wn_conv2 = nn.Sequential(\n",
    "            weight_norm(nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=3, stride=2, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout2d(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # CNNBlock 3\n",
    "        self.wn_conv3 = nn.Sequential(\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=3, stride=1, padding=0), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=1, stride=1, padding=0), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=1, stride=1, padding=0), name='weight'),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "                \n",
    "        # Linear \n",
    "        self.wn_linear = weight_norm(nn.Linear(in_features=filter2, out_features=(num_classes)), name='weight')\n",
    "        self.apply(initializer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional Operations\n",
    "        x = self.wn_conv1(x)\n",
    "        x = self.wn_conv2(x)\n",
    "        x = self.wn_conv3(x)\n",
    "        \n",
    "        # Linear\n",
    "        x = x.mean(dim=3).mean(dim=2)\n",
    "        x = self.wn_linear(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss and model\n",
    "criterion = nn.BCELoss()\n",
    "model = Model()\n",
    "\n",
    "# Data Loader\n",
    "train_loader = get_loader(image_size, batch_size)\n",
    "\n",
    "# Initialize weights\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    criterion.cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train(epoch, num_epochs, optimizer, criterion, dataloader, model):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    loader_len = len(dataloader)\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        img, label = data\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        b_size = img.size(0)\n",
    "    \n",
    "        # Loss computation\n",
    "        probs = model(img)\n",
    "        try:\n",
    "            loss = criterion(probs, label.float())\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Train Accuracy Computation\n",
    "        _, predicted = torch.max(probs, dim=1)\n",
    "        correct = torch.sum(torch.eq(predicted, label))\n",
    "        batch_accuracy = correct.item()/float(b_size)\n",
    "        total_acc += batch_accuracy\n",
    "        \n",
    "        # Print stats\n",
    "        if i%b_size == b_size-1:\n",
    "            print(\"Train [Epoch %d/%d] [Batch %d/%d] [loss: %f, acc: %d%%]\" % (epoch, num_epochs, i, \n",
    "                                       loader_len, loss.item(), 100 * batch_accuracy))\n",
    "            \n",
    "    total_loss = total_loss/float(i+1)\n",
    "    total_acc = total_acc/float(i+1)\n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Function\n",
    "def test(epoch, num_epochs, criterion, dataloader, model, mode):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    loader_len = len(dataloader)\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        \n",
    "        img, label = data\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        b_size = img.size(0)\n",
    "    \n",
    "        # Loss computation\n",
    "        probs = model(img)\n",
    "        loss = criterion(probs, label.float())\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Test Accuracy Computation\n",
    "        _, predicted = torch.max(probs, dim=1)\n",
    "        correct = torch.sum(torch.eq(predicted, label))\n",
    "        batch_accuracy = correct.item()/float(b_size)\n",
    "        total_acc += batch_accuracy\n",
    "        \n",
    "        # Print stats\n",
    "        if i%b_size == b_size-1:\n",
    "            print(\"%s [Epoch %d/%d] [Batch %d/%d] [loss: %f, acc: %d%%]\" % (mode, epoch, num_epochs, i, \n",
    "                                       loader_len, loss.item(), 100 * batch_accuracy))\n",
    "            \n",
    "    total_loss = total_loss/float(i+1)\n",
    "    total_acc = total_acc/float(i+1)\n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best):\n",
    "    if is_best:\n",
    "        torch.save(state, 'baseline_chkpt.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Call Train and Test and save best model\n",
    "'''\n",
    "best_valid_acc = 0.0\n",
    "best_valid_loss = 99999.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(epoch, num_epochs, optimizer, criterion, train_loader, model)\n",
    "    print('------')\n",
    "    valid_loss, valid_acc = test(epoch, num_epochs, criterion, valid_loader, model, 'Valid')\n",
    "    \n",
    "    print('--------------------------------------------------------------------')\n",
    "    print(\"Train ===> [Epoch %d/%d] [Train loss: %f, train acc: %d%%]\" % (epoch, num_epochs, \n",
    "                                                                          train_loss, 100 * train_acc))\n",
    "    print(\"Valid ===> [Epoch %d/%d] [Valid loss: %f, valid acc: %d%%]\" % (epoch, num_epochs, \n",
    "                                                                          valid_loss, 100 * valid_acc))\n",
    "    print('--------------------------------------------------------------------')\n",
    "    \n",
    "    # Save best model\n",
    "    is_best = valid_acc >= best_valid_acc\n",
    "    save_checkpoint({\n",
    "    'epoch': epoch + 1,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer' : optimizer.state_dict(),\n",
    "    'best_acc' : valid_acc\n",
    "    }, is_best)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
