{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class make_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, Y, transform=None, mode='train'):\n",
    "        self.patches = X\n",
    "        self.labels = Y\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return self.transform(self.patches[idx]),self.labels[idx]\n",
    "        else:\n",
    "            return self.transform(self.patches[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Defaults\n",
    "num_epochs = 10 \n",
    "batch_size = 32\n",
    "num_classes = 10 # number of classes for dataset\n",
    "lr = 0.0002 \n",
    "b1 = 0.5 # adam: decay of first order momentum of gradient\n",
    "b2 = 0.999 # adam: decay of first order momentum of gradient\n",
    "n_cpu = 8 # number of cpu threads to use during batch generation\n",
    "latent_dim = 100 # dimensionality of the latent space\n",
    "img_size = 256 # size of each image dimension\n",
    "channels = 1 # number of output image channels\n",
    "sample_interval = 400 # interval between image sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cuda\n",
    "if torch.cuda.is_available():\n",
    "    cuda = True \n",
    "else:\n",
    "    cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.use_gpu = cuda\n",
    "        drop_rate = 0.20\n",
    "        num_classes = 2\n",
    "        input_channels = 3\n",
    "        ndf = 16\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channels, out_channels=ndf, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(drop_rate),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=ndf, out_channels=ndf*2, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(drop_rate),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=ndf*2, out_channels=ndf*4, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(drop_rate),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=ndf*4, out_channels=ndf*8, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(drop_rate),\n",
    "        )\n",
    "        \n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2**4\n",
    "        \n",
    "        # Output layer\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(in_features=128*ds_size**2, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"---------------------------------------\")\n",
    "        #print(\"input size = \", x.size())\n",
    "        x = self.conv1(x)\n",
    "        #print(\"Conv1 output = \", x.size())\n",
    "        x = self.conv2(x)\n",
    "        #print(\"Conv2 output = \", x.size())\n",
    "        x = self.conv3(x)\n",
    "        #print(\"Conv3 output = \", x.size())\n",
    "        x = self.conv4(x)\n",
    "        #print(\"Conv4 output = \", x.size())\n",
    "        \n",
    "        # Flatten the features to give as input to the fc linear classification layer\n",
    "        out = x.view(x.shape[0], -1)\n",
    "        #print(\"Out flatten shape = \", out.size())\n",
    "        out = self.linear1(out)\n",
    "        #print(\"Linear output = \", out.size())\n",
    "        #print(\"---------------------------------------\")\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss and model\n",
    "loss = nn.BCELoss()\n",
    "model = Model()\n",
    "\n",
    "if cuda:\n",
    "    loss.cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "model.apply(weights_init_normal)\n",
    "optimizer = optimizer = torch.optim.Adam(model.parameters(), lr=lr,betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    #import pdb;pdb.set_trace()\n",
    "    n = data['X'].shape[0]\n",
    "    data_X = data['X']\n",
    "    data_Y = data['Y']\n",
    "    train_ratio = 0.7\n",
    "    valid_ratio = 0.1\n",
    "    test_ratio = 0.2\n",
    "    \n",
    "    train_data = data_X[:int(train_ratio*n)]\n",
    "    train_label = data_Y[:int(train_ratio*n)]\n",
    "    valid_data = data_X[int(train_ratio*n):int(train_ratio*n)+int(valid_ratio*n)]\n",
    "    valid_label = data_Y[int(train_ratio*n):int(train_ratio*n)+int(valid_ratio*n)]\n",
    "    test_data = data_X[int(train_ratio*n)+int(valid_ratio*n):]\n",
    "    test_label = data_X[int(train_ratio*n)+int(valid_ratio*n):]\n",
    "    \n",
    "    return train_data,train_label, valid_data,valid_label, test_data,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "dataset_path = '../dataset/training_data.npz'\n",
    "data = np.load(dataset_path)\n",
    "train_data,train_label, valid_data,valid_label,test_data,test_label = split_data(data)\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = make_dataset(train_data,train_label, transformations)\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_data = make_dataset(valid_data,valid_label, transformations)\n",
    "valid_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_data = make_dataset(test_data, test_label, transformations)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train(optimizer, criterion, dataloader, model):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        pdb.set_trace()\n",
    "        \n",
    "        imgs = Variable(imgs.float())\n",
    "        labels = Variable(labels.float())\n",
    "\n",
    "        if cuda:\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Function\n",
    "def test(criterion, dataloader, model, mode = None):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        imgs = Variable(imgs.float())\n",
    "        labels = Variable(labels.float())\n",
    "        \n",
    "        if cuda:\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if mode =='test':\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.long()).sum()\n",
    "                \n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    \n",
    "    if mode == 'test':\n",
    "        test_accuracy = 100 * correct / total\n",
    "        return epoch_loss,test_accuracy\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-28-4c719dd0c674>(10)train()\n",
      "-> imgs = Variable(imgs.float())\n",
      "(Pdb) n\n",
      "> <ipython-input-28-4c719dd0c674>(11)train()\n",
      "-> labels = Variable(labels.float())\n",
      "(Pdb) n\n",
      "> <ipython-input-28-4c719dd0c674>(13)train()\n",
      "-> if cuda:\n",
      "(Pdb) labels\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(optimizer, loss, train_loader, model)\n",
    "    valid_loss = test(loss, valid_loader, model)\n",
    "    test_loss, test_accuracy = test(loss, valid_loader, model,mode='test')\n",
    "    \n",
    "    # Display Progress\n",
    "    print (\"[Epoch %d/%d], Train Loss = %f, Validation Loss = %f, Test Loss = %f, Test Accuracy = %f\" % (epoch, num_epochs, train_loss, \n",
    "                                                                                    valid_loss, test_loss, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
