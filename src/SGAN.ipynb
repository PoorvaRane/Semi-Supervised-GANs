{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.utils import weight_norm\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import pdb\n",
    "import argparse\n",
    "from logger import Logger\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--num_channels NUM_CHANNELS]\n",
      "                   [--num_classes NUM_CLASSES] [--latent_size LATENT_SIZE]\n",
      "                   [--labeled_rate LABELED_RATE] [--batch_size BATCH_SIZE]\n",
      "                   [--num_epochs NUM_EPOCHS] [--image_size IMAGE_SIZE]\n",
      "                   [--epsilon EPSILON]\n",
      "                   [--generator_frequency GENERATOR_FREQUENCY]\n",
      "                   [--discriminator_frequency DISCRIMINATOR_FREQUENCY]\n",
      "                   [--lrD LRD] [--lrG LRG] [--b1 B1] [--b2 B2]\n",
      "                   [--image_dir IMAGE_DIR] [--image_dir_fixed IMAGE_DIR_FIXED]\n",
      "                   [--model_path MODEL_PATH]\n",
      "__main__.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-8fdfa7f8-7d08-4352-9f90-723c63dc963f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--num_channels', type=int, default=3, help='number of channels')\n",
    "parser.add_argument('--num_classes', type=int, default=2, help='number of classes')\n",
    "parser.add_argument('--latent_size', type=int, default=100, help='latent size for noise vector')\n",
    "parser.add_argument('--labeled_rate', type=float, default=0.1, help='ratio of labeled to unlabled samples')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='batch size')\n",
    "parser.add_argument('--num_epochs', type=int, default=500)\n",
    "parser.add_argument('--image_size', type=int, default=32)\n",
    "parser.add_argument('--epsilon', type=float, default=1e-8, help='epsilon')\n",
    "parser.add_argument('--generator_frequency', type=int, default=1, help='generator frequency')\n",
    "parser.add_argument('--discriminator_frequency', type=int, default=1, help='discriminator frequency')\n",
    "parser.add_argument('--lrD', type=float, default=1e-5, help='discriminator learning rate')\n",
    "parser.add_argument('--lrG', type=float, default=1e-5, help='generator learning rate')\n",
    "parser.add_argument('--b1', type=float, default=0.5, help='beta1 for Adam optimizer')\n",
    "parser.add_argument('--b2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
    "parser.add_argument('--image_dir', type=str, default='tcga_images_32', help='directory to save images')\n",
    "parser.add_argument('--model_path', type=str, default='_32.tar', help='directory to save images')\n",
    "parser.add_argument('--mode', type=str, default='train', help='train or test the model')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Print args\n",
    "print('------------ Options -------------')\n",
    "for k, v in sorted(vars(args).items()):\n",
    "    print('%s: %s' % (str(k), str(v)))\n",
    "print('-------------- End ----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-75783589af1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./logs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dir_fixed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "logger = Logger('./logs')\n",
    "\n",
    "os.makedirs(args.image_dir, exist_ok=True)\n",
    "os.makedirs(args.image_dir + '_fixed', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "class TCGADataset(Dataset):\n",
    "    def __init__(self, image_size, split):\n",
    "        self.split = split\n",
    "        self.tcga_dataset = self._create_dataset(image_size, split)\n",
    "        self.patches, self.labels = self.tcga_dataset\n",
    "        self.label_mask = self._create_label_mask()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "        ])\n",
    "#         self.save_images()\n",
    "        \n",
    "    def _create_dataset(self, image_size, split):\n",
    "        data_dir = '/mys3bucket/patch_data'\n",
    "        data_dir = os.path.join(data_dir, self.split)\n",
    "            \n",
    "        all_files = os.listdir(data_dir)\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        # Iterate over all files\n",
    "        for file in all_files:\n",
    "            if '.npz' not in file:\n",
    "                continue\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            data = np.load(file_path)\n",
    "            X = data['arr_0']\n",
    "            y = data['arr_1']\n",
    "            images.append(X)\n",
    "            labels.append(y)\n",
    "            \n",
    "        images = np.concatenate(images)\n",
    "        labels = np.concatenate(labels)        \n",
    "        return images, labels\n",
    "    \n",
    "    def save_images(self):\n",
    "        images = self.patches\n",
    "        folder = 'tcga_check/'\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        for i in range(args.batch_size):\n",
    "            image = images[i]\n",
    "            im = Image.fromarray(image)\n",
    "            im.save(folder + str(i) + '.jpg', format='JPEG')\n",
    "        \n",
    "    def _one_hot(self, y):\n",
    "        label = y\n",
    "        label_onehot = np.zeros(args.num_classes + 1)\n",
    "        label_onehot[label] = 1\n",
    "        return label_onehot\n",
    "    \n",
    "    def _create_label_mask(self):\n",
    "        if self.split == 'train':\n",
    "            l = len(self.labels)\n",
    "            label_mask = np.zeros(l)\n",
    "            masked_len = int(args.labeled_rate * l)\n",
    "            label_mask[0:masked_len] = 1\n",
    "            np.random.shuffle(label_mask)\n",
    "            label_mask = torch.LongTensor(label_mask)\n",
    "            if torch.cuda.is_available(): \n",
    "                label_mask = label_mask.cuda()\n",
    "            return label_mask\n",
    "        return None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.patches[idx], self.labels[idx]\n",
    "        label_onehot = self._one_hot(label)\n",
    "        if self.split == 'train':\n",
    "            return self.transform(Image.fromarray(data)), label, label_onehot, self.label_mask[idx]\n",
    "        return self.transform(Image.fromarray(data)), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dataloaders\n",
    "def get_loader(image_size, batch_size):\n",
    "    #num_workers = 2\n",
    "\n",
    "    tcga_train = TCGADataset(image_size=image_size, split='train')\n",
    "    tcga_dev = TCGADataset(image_size=image_size, split='dev')\n",
    "#     tcga_test = TCGADataset(image_size=image_size, split='test')\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=tcga_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "        #num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    dev_loader = DataLoader(\n",
    "        dataset=tcga_dev,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "        #num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "#     test_loader = DataLoader(\n",
    "#         dataset=tcga_test,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=True\n",
    "#         #num_workers=num_workers\n",
    "#     )\n",
    "\n",
    "    return train_loader, dev_loader#, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initializer(m):\n",
    "    # Run xavier on all weights and zero all biases\n",
    "    if hasattr(m, 'weight'):\n",
    "        if m.weight.ndimension() > 1:\n",
    "            xavier_uniform_(m.weight.data)\n",
    "\n",
    "    if hasattr(m, 'bias') and m.bias is not None:\n",
    "        m.bias.data.zero_() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GaussianNoise(torch.nn.Module):\n",
    "    def __init__(self, sigma):\n",
    "        super(GaussianNoise, self).__init__()\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            noise = x.new(x.size()).normal_(std=self.sigma)\n",
    "            return x + noise\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "          \n",
    "        dropout_rate = 0.5\n",
    "        filter1 = 96\n",
    "        filter2 = 192\n",
    "        \n",
    "        self.begin = nn.Sequential(\n",
    "            GaussianNoise(0.05),\n",
    "            nn.Dropout2d(0.2)   \n",
    "        )\n",
    "        \n",
    "        # Conv operations\n",
    "        # CNNBlock 1\n",
    "        self.wn_conv1 = nn.Sequential(\n",
    "            weight_norm(nn.Conv2d(in_channels=args.num_channels, out_channels=filter1, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter1, out_channels=filter1, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter1, out_channels=filter1, kernel_size=3, stride=2, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout2d(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # CNNBlock 2\n",
    "        self.wn_conv2 = nn.Sequential(\n",
    "            weight_norm(nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=3, stride=2, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout2d(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # CNNBlock 3\n",
    "        self.wn_conv3 = nn.Sequential(\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=3, stride=1, padding=0), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=1, stride=1, padding=0), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=1, stride=1, padding=0), name='weight'),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "                \n",
    "        # Linear \n",
    "        self.wn_linear = weight_norm(nn.Linear(in_features=filter2, out_features=(args.num_classes + 1)), name='weight')\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.apply(initializer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.begin(x)\n",
    "        # Convolutional Operations\n",
    "        x = self.wn_conv1(x)\n",
    "        x = self.wn_conv2(x)\n",
    "        x = self.wn_conv3(x)\n",
    "        \n",
    "        # Linear\n",
    "        flatten = x.mean(dim=3).mean(dim=2)\n",
    "        linear = self.wn_linear(flatten)\n",
    "        prob = self.softmax(linear)\n",
    "        return flatten, linear, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(in_features=args.latent_size, out_features=4 * 4 * 512, bias=False),\n",
    "            nn.BatchNorm1d(4 * 4 * 512),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        # Conv operations\n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.deconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.wn_deconv3 = nn.Sequential(\n",
    "            weight_norm(nn.ConvTranspose2d(in_channels=128, out_channels=3, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "                        name='weight'),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.apply(initializer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = x.view(-1, 512, 4, 4)\n",
    "        \n",
    "        # Deconvolutional Operations\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.wn_deconv3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    if torch.cuda.is_available(): \n",
    "        return n.cuda() \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "discriminator = DiscriminatorNet()\n",
    "generator = GeneratorNet()\n",
    "\n",
    "# Data Loader\n",
    "train_loader, dev_loader = get_loader(args.image_size, args.batch_size)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=args.lrD, betas=(args.b1, args.b2))\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=args.lrG, betas=(args.b1, args.b2))\n",
    "\n",
    "# Loss\n",
    "cross_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    discriminator = discriminator.cuda()\n",
    "    generator = generator.cuda()\n",
    "    discriminator = nn.DataParallel(discriminator)\n",
    "    generator = nn.DataParallel(generator)\n",
    "    cross_loss = cross_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize Data\n",
    "def plot_fake_data(data, grid_size = [5, 5]):\n",
    "    _, axes = plt.subplots(figsize = grid_size, nrows = grid_size[0], ncols = grid_size[1],\n",
    "                           sharey = True, sharex = True)\n",
    "\n",
    "    size = grid_size[0] * grid_size[1]\n",
    "    index = np.int_(np.random.uniform(0, data.shape[0], size = (size)))\n",
    "\n",
    "    figs = data[index].reshape(-1, args.image_size, args.image_size)\n",
    "\n",
    "    for idx, ax in enumerate(axes.flatten()):\n",
    "        ax.axis('off')\n",
    "        ax.imshow(figs[idx], cmap = 'gray')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer_D, b_size, img, label, label_mask, epsilon):\n",
    "    \n",
    "    # Generate Fake Image\n",
    "    z = noise(b_size)\n",
    "    fake_img = generator(z)\n",
    "\n",
    "    # Discriminator outputs for real and fake\n",
    "    d_real_flatten, d_real_linear, d_real_prob = discriminator(img)\n",
    "    d_fake_flatten, d_fake_linear, d_fake_prob = discriminator(fake_img.detach())\n",
    "    \n",
    "    optimizer_D.zero_grad()\n",
    "        \n",
    "    # Supervised Loss\n",
    "    supervised_loss = cross_loss(d_real_linear, label)\n",
    "\n",
    "    masked_supervised_loss = torch.mul(label_mask, supervised_loss)\n",
    "    delim = torch.Tensor([1.0])\n",
    "    if torch.cuda.is_available():\n",
    "        delim = delim.cuda()\n",
    "    mask_sum = torch.max(delim, torch.sum(label_mask))\n",
    "    d_class_loss = torch.sum(label_mask * masked_supervised_loss) / mask_sum\n",
    "\n",
    "    # Unsupervised (GAN) Loss\n",
    "    # data is real\n",
    "    prob_real_is_real = 1.0 - d_real_prob[:, -1] + epsilon\n",
    "    tmp_log = torch.log(prob_real_is_real)\n",
    "    d_real_loss = -1.0 * torch.mean(tmp_log)\n",
    "\n",
    "    # data is fake\n",
    "    prob_fake_is_fake = d_fake_prob[:, -1] + epsilon\n",
    "    tmp_log = torch.log(prob_fake_is_fake)\n",
    "    d_fake_loss = -1.0 * torch.mean(tmp_log)\n",
    "\n",
    "    # loss and weight update\n",
    "    d_loss = d_class_loss + d_real_loss + d_fake_loss\n",
    "    d_loss.backward(retain_graph=True)\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    # Accuracy\n",
    "    _, predicted = torch.max(d_real_prob[:, :-1], dim=1)\n",
    "    correct_batch = torch.sum(torch.eq(predicted, label))\n",
    "    batch_accuracy = correct_batch.item()/float(b_size)\n",
    "    \n",
    "    return d_loss, batch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_discriminator(b_size, img, label):\n",
    "    \n",
    "    # Generate Fake Image\n",
    "    z = noise(b_size)\n",
    "    fake_img = generator(z)\n",
    "\n",
    "    # Discriminator outputs for real and fake\n",
    "    d_real_flatten, d_real_linear, d_real_prob = discriminator(img)\n",
    "    d_fake_flatten, d_fake_linear, d_fake_prob = discriminator(fake_img.detach())\n",
    "    \n",
    "    # Accuracy\n",
    "    _, predicted = torch.max(d_real_prob[:, :-1], dim=1)\n",
    "    correct_batch = torch.sum(torch.eq(predicted, label))\n",
    "    batch_accuracy = correct_batch.item()/float(b_size)\n",
    "    \n",
    "    return batch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(optimizer_G, b_size, epsilon):\n",
    "    \n",
    "    # Generate Fake Image\n",
    "    z = noise(b_size)\n",
    "    fake_img = generator(z)\n",
    "\n",
    "    # Discriminator outputs for real and fake\n",
    "    d_real_flatten, d_real_linear, d_real_prob = discriminator(img)\n",
    "    d_fake_flatten, d_fake_linear, d_fake_prob = discriminator(fake_img)\n",
    "    \n",
    "    optimizer_G.zero_grad()\n",
    "        \n",
    "    # fake data is mistaken to be real\n",
    "    prob_fake_is_real = 1.0 - d_fake_prob[:, -1] + epsilon\n",
    "    tmp_log =  torch.log(prob_fake_is_real)\n",
    "    g_fake_loss = -1.0 * torch.mean(tmp_log)\n",
    "\n",
    "    # Feature Maching\n",
    "    tmp1 = torch.mean(d_real_flatten, dim = 0)\n",
    "    tmp2 = torch.mean(d_fake_flatten, dim = 0)\n",
    "    diff = tmp1 - tmp2\n",
    "    g_feature_loss = torch.mean(torch.mul(diff, diff))\n",
    "\n",
    "    # Loss and weight update\n",
    "    g_loss = g_fake_loss + g_feature_loss\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    return g_loss, fake_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best):\n",
    "    torch.save(state, args.model_path)\n",
    "    if is_best:\n",
    "        shutil.copyfile(model_type + args.model_path, 'best_' +args.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_module(epoch, train_loader):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    total_train_accuracy = 0\n",
    "    G_loss = 0\n",
    "    D_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        img, label, label_onehot, label_mask = data\n",
    "        label_mask = label_mask.float()\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            label_onehot = label_onehot.cuda()\n",
    "            label_mask = label_mask.cuda()\n",
    "        \n",
    "        b_size = img.size(0)\n",
    "        \n",
    "        ################### Discriminator ####################\n",
    "        batch_d_loss = 0\n",
    "        batch_accuracy = 0\n",
    "        \n",
    "        for d_i in range(args.discriminator_frequency):\n",
    "            d_loss, d_accuracy = train_discriminator(optimizer_D, b_size, img, label, label_mask, args.epsilon)\n",
    "            batch_d_loss += d_loss.item()  \n",
    "            batch_accuracy += d_accuracy\n",
    "            \n",
    "        batch_d_loss = batch_d_loss/float(args.discriminator_frequency)\n",
    "        train_batch_accuracy = batch_accuracy/float(args.discriminator_frequency)\n",
    "        \n",
    "        ################### Generator ####################\n",
    "        batch_g_loss = 0\n",
    "        for g_i in range(args.generator_frequency):\n",
    "            g_loss, fake_img = train_generator(optimizer_G, b_size, args.epsilon)\n",
    "            batch_g_loss += g_loss.item()\n",
    "        batch_g_loss = batch_g_loss/float(args.generator_frequency)\n",
    "       \n",
    "        total_train_accuracy += train_batch_accuracy\n",
    "        D_loss += batch_d_loss\n",
    "        G_loss += batch_g_loss    \n",
    "        \n",
    "        if i%b_size == b_size-1:\n",
    "            print(\"Train [Epoch %d/%d] [Batch %d/%d] [D loss: %f, train acc: %.3f%%] [G loss: %f]\" % (epoch, args.num_epochs,\n",
    "                          i, len(train_loader), batch_d_loss, 100 * train_batch_accuracy, batch_g_loss))\n",
    "\n",
    "    # Epoch Stats\n",
    "    total_train_accuracy = total_train_accuracy/float(i+1)\n",
    "    D_loss = D_loss/float(i+1)\n",
    "    G_loss = G_loss/float(i+1)\n",
    "\n",
    "    return total_train_accuracy, D_loss, G_loss, fake_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_module(dev_loader):\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    total_dev_accuracy = 0\n",
    "\n",
    "    for i, data in enumerate(dev_loader):\n",
    "        \n",
    "        img, label = data\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        b_size = img.size(0)\n",
    "        dev_accuracy = test_discriminator(b_size, img, label)\n",
    "        total_dev_accuracy += dev_accuracy\n",
    "        \n",
    "    # Epoch Stats\n",
    "    total_dev_accuracy = total_dev_accuracy/float(i+1)\n",
    "    return total_dev_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensorboard_logging(epoch, G_loss, D_loss, total_train_accuracy, total_dev_accuracy, fake_img):\n",
    "    # 1. Log scalar values (scalar summary)\n",
    "    info = { 'Epoch': epoch, 'G_loss': G_loss, 'D_loss': D_loss, 'train_accuracy': total_train_accuracy, 'dev_accuracy': total_dev_accuracy }\n",
    "    for tag, value in info.items():\n",
    "        logger.scalar_summary(tag, value, epoch)\n",
    "    \n",
    "    # 2. Log values and gradients of the parameters (histogram summary)\n",
    "    # Generator summary\n",
    "    for tag, value in generator.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        logger.histo_summary(tag, value.detach().cpu().numpy(), epoch)\n",
    "        logger.histo_summary(tag+'/grad', value.grad.detach().cpu().numpy(), epoch)\n",
    "    \n",
    "    #Discriminator summary\n",
    "    for tag, value in discriminator.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        logger.histo_summary(tag, value.detach().cpu().numpy(), epoch)\n",
    "        logger.histo_summary(tag+'/grad', value.grad.detach().cpu().numpy(), epoch)\n",
    "        \n",
    "    # 3. Log generated images (image summary)\n",
    "    info = { args.image_dir : fake_img.view(-1, args.image_size, args.image_size)[:10].detach().cpu().numpy() }\n",
    "\n",
    "    for tag, images in info.items():\n",
    "        logger.image_summary(tag, images, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-12-b74075518538>(42)train_discriminator()\n",
      "-> _, predicted = torch.max(d_real_prob[:, :-1], dim=1)\n",
      "(Pdb) d_real_prob.size()\n",
      "torch.Size([32, 3])\n",
      "(Pdb) d_real_prob[:,:-1].size()\n",
      "torch.Size([32, 2])\n",
      "(Pdb) d_real_prob[:,:-1]\n",
      "tensor([[0.3333, 0.3332],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.3332],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3335, 0.3333],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.3332],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3334, 0.3332],\n",
      "        [0.3333, 0.3332],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3334, 0.3332],\n",
      "        [0.3334, 0.3332],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.3331],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3334, 0.3331],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.3331],\n",
      "        [0.3334, 0.3331],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.3332],\n",
      "        [0.3334, 0.3333],\n",
      "        [0.3334, 0.3332],\n",
      "        [0.3334, 0.3333],\n",
      "        [0.3333, 0.3331],\n",
      "        [0.3334, 0.3332]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "(Pdb) predicted.size()\n",
      "*** NameError: name 'predicted' is not defined\n",
      "(Pdb) _, predicted = torch.max(d_real_prob[:, :-1], dim=1)\n",
      "(Pdb) predicted.size()\n",
      "torch.Size([32])\n",
      "(Pdb) predicted\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9a92cf0acf47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mbatch_d_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mbatch_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b74075518538>\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[0;34m(optimizer_D, b_size, img, label, label_mask, epsilon)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_real_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mcorrect_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mbatch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b74075518538>\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[0;34m(optimizer_D, b_size, img, label, label_mask, epsilon)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_real_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mcorrect_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mbatch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main_module():\n",
    "    # Fixed noise vector\n",
    "    fixed_z = noise(args.batch_size)\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "\n",
    "        # Training\n",
    "        total_train_accuracy, D_loss, G_loss, fake_img = training_module(train_loader)\n",
    "        # Evaluation \n",
    "        total_dev_accuracy = eval_module(dev_loader)\n",
    "\n",
    "        # Save best model\n",
    "        is_best = total_dev_accuracy >= total_train_accuracy\n",
    "\n",
    "        save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'dis_state_dict': discriminator.state_dict(),\n",
    "        'optimizer_D' : optimizer_D.state_dict(),\n",
    "        'gen_state_dict': generator.state_dict(),\n",
    "        'optimizer_G' : optimizer_G.state_dict(),\n",
    "        }, is_best)\n",
    "        \n",
    "        print('--------------------------------------------------------------------')\n",
    "        print(\"===> [Epoch %d/%d] [Avg D loss: %f, avg train acc: %.3f%%, avg dev acc: %.3f%%] [Avg G loss: %f]\" % (epoch, args.num_epochs, \n",
    "                                                      D_loss, 100 * total_train_accuracy, 100* total_dev_accuracy, G_loss))\n",
    "        print('--------------------------------------------------------------------')\n",
    "        \n",
    "        # Save Images\n",
    "        save_image(fake_img, args.image_dir + '/epoch_%d_batch_%d.png' % (epoch, i), nrow=8, normalize=True)\n",
    "        # Save Fixed Images\n",
    "        fixed_fake_img = generator(fixed_z)\n",
    "        save_image(fixed_fake_img, args.image_dir + '_fixed' + '/epoch_%d_batch_%d.png' % (epoch, i), nrow=8, normalize=True)\n",
    "        \n",
    "        # Tensorboard logging \n",
    "        tensorboard_logging(epoch, G_loss, D_loss, total_train_accuracy, total_dev_accuracy, fake_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_module():\n",
    "\n",
    "    # Load the saved model for discriminator\n",
    "    BEST_DISCRIMINATOR = 'dis32_lr.tar'\n",
    "    if os.path.isfile(BEST_DISCRIMINATOR):\n",
    "        print(\"=> loading dis checkpoint\")\n",
    "        checkpoint = torch.load(BEST_DISCRIMINATOR)\n",
    "        discriminator.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer_D.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(BEST_DISCRIMINATOR, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(BEST_DISCRIMINATOR))\n",
    "\n",
    "    # Load the saved model for generator\n",
    "    BEST_GENERATOR = 'gen32_lr.tar'\n",
    "    if os.path.isfile(BEST_GENERATOR):\n",
    "        print(\"=> loading gen checkpoint\")\n",
    "        checkpoint = torch.load(BEST_GENERATOR)\n",
    "        generator.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer_G.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(BEST_GENERATOR, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(BEST_GENERATOR))\n",
    "\n",
    "    '''\n",
    "    # Load the best model\n",
    "    BEST_MODEL = '32_lr.tar'\n",
    "    if os.path.isfile(BEST_MODEL):\n",
    "        print(\"=> loading dis checkpoint\")\n",
    "        checkpoint = torch.load(BEST_MODEL)\n",
    "        discriminator.load_state_dict(checkpoint['dis_state_dict'])\n",
    "        optimizer_D.load_state_dict(checkpoint['optimizer_D'])\n",
    "        generator.load_state_dict(checkpoint['gen_state_dict'])\n",
    "        optimizer_G.load_state_dict(checkpoint['optimizer_G'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(BEST_MODEL, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(BEST_MODEL))\n",
    "    '''\n",
    "\n",
    "    total_dev_accuracy = eval_module(dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if args.mode == 'train':\n",
    "    # Train a model and save the best one\n",
    "    main_module()\n",
    "else:\n",
    "    # Test model performance on Dev/Test data\n",
    "    testing_module(dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
