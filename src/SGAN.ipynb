{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.utils import weight_norm\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import pdb\n",
    "from logger import Logger\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "num_channels = 3\n",
    "num_classes = 10\n",
    "latent_size = 100\n",
    "labeled_rate = 0.1\n",
    "num_epochs = 1000\n",
    "image_size = 32\n",
    "batch_size = 32\n",
    "epsilon = 1e-8 # used to avoid NAN loss\n",
    "generator_frequency = 1\n",
    "discriminator_frequency = 1\n",
    "logger = Logger('./logs')\n",
    "\n",
    "# Initialize parameters\n",
    "lr = 1e-5\n",
    "b1 = 0.5 # adam: decay of first order momentum of gradient\n",
    "b2 = 0.999 # adam: decay of first order momentum of gradient\n",
    "\n",
    "log_path = './SSL_TCGA_log.csv'\n",
    "model_path ='./TCGA_32.tar'\n",
    "image_dir = 'tcga_images_32'\n",
    "\n",
    "os.makedirs(image_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "class TCGADataset(Dataset):\n",
    "    def __init__(self, image_size, split):\n",
    "        self.split = split\n",
    "        self.tcga_dataset = self._create_dataset(image_size, split)\n",
    "        self.patches, self.labels = self.tcga_dataset\n",
    "        self.label_mask = self._create_label_mask()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "        ])\n",
    "#         self.save_images()\n",
    "        \n",
    "    def _create_dataset(self, image_size, split):\n",
    "        data_dir = '../dataset/patch_data'\n",
    "        if self.split == 'train':\n",
    "            data_dir = os.path.join(data_dir, 'train')\n",
    "        else:\n",
    "            data_dir = os.path.join(data_dir, 'dev')\n",
    "            \n",
    "        all_files = ['5.npz', '6.npz', '7.npz', '8.npz', '9.npz', '10.npz'] #os.listdir(data_dir)\n",
    "        #all_files = ['5.npz']\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        # Iterate over all files\n",
    "        for file in all_files:\n",
    "            if '.npz' not in file:\n",
    "                continue\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            data = np.load(file_path)\n",
    "            X = data['arr_0']\n",
    "            y = data['arr_1']\n",
    "            images.append(X)\n",
    "            labels.append(y)\n",
    "            \n",
    "        images = np.concatenate(images)\n",
    "        labels = np.concatenate(labels)\n",
    "        return images, labels\n",
    "    \n",
    "    def save_images(self):\n",
    "        images = self.patches\n",
    "        folder = 'tcga_check/'\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        for i in range(batch_size):\n",
    "            image = images[i]\n",
    "            im = Image.fromarray(image)\n",
    "            im.save(folder + str(i) + '.jpg', format='JPEG')\n",
    "        \n",
    "    def _one_hot(self, y):\n",
    "        label = y\n",
    "        label_onehot = np.zeros(num_classes + 1)\n",
    "        label_onehot[label] = 1\n",
    "        return label_onehot\n",
    "    \n",
    "    def _create_label_mask(self):\n",
    "        if self.split == 'train':\n",
    "            l = len(self.labels)\n",
    "            label_mask = np.zeros(l)\n",
    "            masked_len = int(labeled_rate * l)\n",
    "            label_mask[0:masked_len] = 1\n",
    "            np.random.shuffle(label_mask)\n",
    "            label_mask = torch.LongTensor(label_mask)\n",
    "            if torch.cuda.is_available(): \n",
    "                label_mask = label_mask.cuda()\n",
    "            return label_mask\n",
    "        return None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.patches[idx], self.labels[idx]\n",
    "        if label in [330.0,331.0]:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        label_onehot = self._one_hot(label)\n",
    "        if self.split == 'train':\n",
    "            return self.transform(Image.fromarray(data)), label, label_onehot, self.label_mask[idx]\n",
    "        return self.transform(Image.fromarray(data)), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataloaders\n",
    "def get_loader(image_size, batch_size):\n",
    "    #num_workers = 2\n",
    "\n",
    "    tcga_train = TCGADataset(image_size=image_size, split='train')\n",
    "#     tcga_test = TCGADataset(image_size=image_size, split='test')\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=tcga_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "        #num_workers=num_workers\n",
    "    )\n",
    "\n",
    "#     test_loader = DataLoader(\n",
    "#         dataset=tcga_test,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=True\n",
    "#         #num_workers=num_workers\n",
    "#     )\n",
    "\n",
    "    return train_loader#, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer(m):\n",
    "    # Run xavier on all weights and zero all biases\n",
    "    if hasattr(m, 'weight'):\n",
    "        if m.weight.ndimension() > 1:\n",
    "            xavier_uniform_(m.weight.data)\n",
    "\n",
    "    if hasattr(m, 'bias') and m.bias is not None:\n",
    "        m.bias.data.zero_() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(torch.nn.Module):\n",
    "    def __init__(self, sigma):\n",
    "        super(GaussianNoise, self).__init__()\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            noise = x.new(x.size()).normal_(std=self.sigma)\n",
    "            return x + noise\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "          \n",
    "        dropout_rate = 0.5\n",
    "        filter1 = 96\n",
    "        filter2 = 192\n",
    "        \n",
    "        self.begin = nn.Sequential(\n",
    "            GaussianNoise(0.05),\n",
    "            nn.Dropout2d(0.2)   \n",
    "        )\n",
    "        \n",
    "        # Conv operations\n",
    "        # CNNBlock 1\n",
    "        self.wn_conv1 = nn.Sequential(\n",
    "            weight_norm(nn.Conv2d(in_channels=num_channels, out_channels=filter1, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter1, out_channels=filter1, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter1, out_channels=filter1, kernel_size=3, stride=2, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout2d(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # CNNBlock 2\n",
    "        self.wn_conv2 = nn.Sequential(\n",
    "            weight_norm(nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=3, stride=1, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=3, stride=2, padding=1), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout2d(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # CNNBlock 3\n",
    "        self.wn_conv3 = nn.Sequential(\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=3, stride=1, padding=0), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=1, stride=1, padding=0), name='weight'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=filter2, out_channels=filter2, kernel_size=1, stride=1, padding=0), name='weight'),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "                \n",
    "        # Linear \n",
    "        self.wn_linear = weight_norm(nn.Linear(in_features=filter2, out_features=(num_classes + 1)), name='weight')\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.apply(initializer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.begin(x)\n",
    "        # Convolutional Operations\n",
    "        x = self.wn_conv1(x)\n",
    "        x = self.wn_conv2(x)\n",
    "        x = self.wn_conv3(x)\n",
    "        \n",
    "        # Linear\n",
    "        flatten = x.mean(dim=3).mean(dim=2)\n",
    "        linear = self.wn_linear(flatten)\n",
    "        prob = self.softmax(linear)\n",
    "        return flatten, linear, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(in_features=latent_size, out_features=4 * 4 * 512, bias=False),\n",
    "            nn.BatchNorm1d(4 * 4 * 512),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        # Conv operations\n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.deconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.wn_deconv3 = nn.Sequential(\n",
    "            weight_norm(nn.ConvTranspose2d(in_channels=128, out_channels=3, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "                        name='weight'),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.apply(initializer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = x.view(-1, 512, 4, 4)\n",
    "        \n",
    "        # Deconvolutional Operations\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.wn_deconv3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    if torch.cuda.is_available(): \n",
    "        return n.cuda() \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "discriminator = DiscriminatorNet()\n",
    "generator = GeneratorNet()\n",
    "\n",
    "# Data Loader\n",
    "train_loader = get_loader(image_size, batch_size)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# Loss\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "cross_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    discriminator = discriminator.cuda()\n",
    "    generator = generator.cuda()\n",
    "    discriminator = nn.DataParallel(discriminator)\n",
    "    generator = nn.DataParallel(generator)\n",
    "    bce_loss = bce_loss.cuda()\n",
    "    cross_loss = cross_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Data\n",
    "def plot_fake_data(data, grid_size = [5, 5]):\n",
    "    _, axes = plt.subplots(figsize = grid_size, nrows = grid_size[0], ncols = grid_size[1],\n",
    "                           sharey = True, sharex = True)\n",
    "\n",
    "    size = grid_size[0] * grid_size[1]\n",
    "    index = np.int_(np.random.uniform(0, data.shape[0], size = (size)))\n",
    "\n",
    "    figs = data[index].reshape(-1, image_size, image_size)\n",
    "\n",
    "    for idx, ax in enumerate(axes.flatten()):\n",
    "        ax.axis('off')\n",
    "        ax.imshow(figs[idx], cmap = 'gray')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer_D, b_size, img, label, label_mask, epsilon):\n",
    "    \n",
    "    # Generate Fake Image\n",
    "    z = noise(b_size)\n",
    "    fake_img = generator(z)\n",
    "\n",
    "    # Discriminator outputs for real and fake\n",
    "    d_real_flatten, d_real_linear, d_real_prob = discriminator(img)\n",
    "    d_fake_flatten, d_fake_linear, d_fake_prob = discriminator(fake_img.detach())\n",
    "    \n",
    "    optimizer_D.zero_grad()\n",
    "        \n",
    "    # Supervised Loss\n",
    "    supervised_loss = cross_loss(d_real_linear, label)\n",
    "#   d_class_loss_entropy = - torch.sum(label_onehot.float() * torch.log(d_real_prob), dim=1)\n",
    "\n",
    "    masked_supervised_loss = torch.mul(label_mask, supervised_loss)\n",
    "    delim = torch.Tensor([1.0])\n",
    "    if torch.cuda.is_available():\n",
    "        delim = delim.cuda()\n",
    "    mask_sum = torch.max(delim, torch.sum(label_mask))\n",
    "    d_class_loss = torch.sum(label_mask * masked_supervised_loss) / mask_sum\n",
    "\n",
    "    # Unsupervised (GAN) Loss\n",
    "    # data is real\n",
    "    prob_real_is_real = 1.0 - d_real_prob[:, -1] + epsilon\n",
    "    tmp_log = torch.log(prob_real_is_real)\n",
    "    d_real_loss = -1.0 * torch.mean(tmp_log)\n",
    "\n",
    "    # data is fake\n",
    "    prob_fake_is_fake = d_fake_prob[:, -1] + epsilon\n",
    "    tmp_log = torch.log(prob_fake_is_fake)\n",
    "    d_fake_loss = -1.0 * torch.mean(tmp_log)\n",
    "\n",
    "    # loss and weight update\n",
    "    d_loss = d_class_loss + d_real_loss + d_fake_loss\n",
    "    d_loss.backward(retain_graph=True)\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    # Accuracy\n",
    "    _, predicted = torch.max(d_real_prob[:, :-1], dim=1)\n",
    "    correct_batch = torch.sum(torch.eq(predicted, label))\n",
    "    batch_accuracy = correct_batch.item()/float(b_size)\n",
    "    \n",
    "    return d_loss, batch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(optimizer_G, b_size, epsilon):\n",
    "    \n",
    "    # Generate Fake Image\n",
    "    z = noise(b_size)\n",
    "    fake_img = generator(z)\n",
    "\n",
    "    # Discriminator outputs for real and fake\n",
    "    d_real_flatten, d_real_linear, d_real_prob = discriminator(img)\n",
    "    d_fake_flatten, d_fake_linear, d_fake_prob = discriminator(fake_img)\n",
    "    \n",
    "    optimizer_G.zero_grad()\n",
    "        \n",
    "    # fake data is mistaken to be real\n",
    "    prob_fake_is_real = 1.0 - d_fake_prob[:, -1] + epsilon\n",
    "    tmp_log =  torch.log(prob_fake_is_real)\n",
    "    g_fake_loss = -1.0 * torch.mean(tmp_log)\n",
    "\n",
    "    # Feature Maching\n",
    "    tmp1 = torch.mean(d_real_flatten, dim = 0)\n",
    "    tmp2 = torch.mean(d_fake_flatten, dim = 0)\n",
    "    diff = tmp1 - tmp2\n",
    "    g_feature_loss = torch.mean(torch.mul(diff, diff))\n",
    "\n",
    "    # Loss and weight update\n",
    "    g_loss = g_fake_loss + g_feature_loss\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    return g_loss, fake_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, model_type):\n",
    "    torch.save(state, model_type + '_checkpoint_32.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-522c6feb8401>(30)train_generator()\n",
      "-> return g_loss, fake_img\n",
      "(Pdb) for f in generator.parameters(): print(f.grad)\n",
      "tensor([[ 4.5292e-09,  1.0688e-09,  2.0401e-09,  ..., -8.0876e-10,\n",
      "          8.4940e-11, -6.4153e-10],\n",
      "        [-2.3422e-08, -1.7789e-08, -3.4604e-08,  ...,  9.0432e-09,\n",
      "          3.3505e-09,  1.7336e-08],\n",
      "        [-2.9405e-09, -1.2607e-08,  9.3743e-09,  ...,  3.2610e-09,\n",
      "         -5.0036e-09,  6.1438e-09],\n",
      "        ...,\n",
      "        [-7.9222e-09,  9.6403e-09, -3.4905e-09,  ..., -7.1506e-10,\n",
      "         -1.4235e-08,  1.0217e-09],\n",
      "        [ 2.5308e-09,  1.6418e-09,  1.7607e-09,  ..., -1.7408e-09,\n",
      "         -1.5527e-09,  1.7118e-09],\n",
      "        [ 5.4236e-09,  3.5499e-09, -6.5185e-09,  ..., -1.5822e-09,\n",
      "          1.1206e-08, -2.6774e-09]], device='cuda:0')\n",
      "tensor([-2.1851e-09,  4.8094e-10,  2.4587e-09,  ...,  1.0316e-09,\n",
      "         3.0634e-09, -4.0633e-09], device='cuda:0')\n",
      "tensor([-3.2164e-09,  1.7568e-10,  2.5609e-09,  ..., -3.7760e-10,\n",
      "         1.5044e-09, -7.8707e-10], device='cuda:0')\n",
      "tensor([[[[ 4.4029e-09,  2.2258e-08, -2.1624e-08, -1.8633e-08,  1.6268e-09],\n",
      "          [ 1.9010e-08, -1.1402e-08,  1.7023e-08, -7.5976e-09,  2.9680e-08],\n",
      "          [ 4.3692e-09, -1.1913e-08,  3.5945e-09, -1.0927e-08, -1.6908e-08],\n",
      "          [ 3.7135e-09,  5.4773e-09,  3.9720e-10,  1.3015e-09,  1.9897e-08],\n",
      "          [ 4.2969e-09,  9.6921e-09, -1.6862e-08,  1.7219e-09,  8.3269e-09]],\n",
      "\n",
      "         [[-4.9467e-09,  7.3907e-10,  1.7178e-09,  3.6477e-10, -2.0046e-09],\n",
      "          [ 3.2306e-09,  5.9393e-09, -2.3850e-09, -4.4016e-09, -4.5673e-09],\n",
      "          [-3.9215e-10,  2.3742e-09, -4.3674e-09,  3.0260e-09, -2.2515e-09],\n",
      "          [-3.0804e-09, -4.7459e-10, -2.1944e-09, -1.9552e-09,  4.2615e-09],\n",
      "          [-3.1305e-09,  3.7590e-09,  5.3019e-10,  4.2508e-09,  2.5653e-09]],\n",
      "\n",
      "         [[ 7.3301e-09,  1.5504e-09, -5.9032e-09, -1.1449e-08, -9.1170e-10],\n",
      "          [-1.3011e-08,  7.6017e-09,  1.8090e-09, -2.7656e-08, -1.1906e-08],\n",
      "          [ 9.7825e-09, -2.6144e-09,  1.2066e-08, -1.3167e-08,  5.8381e-09],\n",
      "          [ 6.0070e-09, -1.3926e-08,  1.2951e-08, -5.3547e-10,  1.3103e-08],\n",
      "          [-2.1059e-09, -4.5979e-09, -2.4331e-09,  1.3293e-09, -6.7719e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8634e-09, -6.9412e-09, -4.4800e-09, -9.7649e-09, -3.1957e-09],\n",
      "          [ 1.3836e-09, -1.3333e-08, -8.7204e-10, -1.7394e-08, -9.1258e-10],\n",
      "          [ 1.8835e-09,  5.7635e-10, -1.6202e-09, -7.2062e-10,  3.9094e-09],\n",
      "          [ 3.0298e-09,  1.5199e-09,  6.0461e-09,  1.2112e-09,  4.8570e-09],\n",
      "          [ 5.6390e-10,  2.9036e-09,  7.7184e-09,  7.2561e-09, -3.0674e-09]],\n",
      "\n",
      "         [[ 1.2726e-09,  4.2836e-09,  4.7474e-09,  5.9665e-09, -2.7932e-09],\n",
      "          [ 3.4773e-10, -3.6770e-09, -5.4605e-10, -1.0569e-09, -1.7264e-09],\n",
      "          [ 3.6918e-09,  3.6098e-09, -1.7353e-10,  6.8021e-09,  7.9534e-11],\n",
      "          [ 8.0719e-09, -5.5733e-10,  7.1824e-09, -6.0810e-09,  6.8147e-09],\n",
      "          [ 2.8448e-09,  1.3146e-08, -2.4901e-10, -5.2312e-09,  2.1702e-09]],\n",
      "\n",
      "         [[ 2.9587e-10, -2.2450e-09,  6.0245e-09,  1.2982e-08, -3.5430e-11],\n",
      "          [-1.3121e-08,  7.6595e-09, -1.5906e-08,  2.6999e-08, -1.4937e-08],\n",
      "          [-4.3962e-09,  1.4315e-08,  9.8848e-09, -7.7810e-09, -1.8521e-08],\n",
      "          [-7.6775e-10, -1.8243e-09, -1.1706e-08,  1.5641e-08, -2.8322e-09],\n",
      "          [-7.0105e-09,  9.8301e-11, -6.3692e-09, -1.0129e-08,  1.4525e-09]]],\n",
      "\n",
      "\n",
      "        [[[-6.0572e-09,  1.2562e-08, -1.7693e-08,  8.3963e-10,  3.3947e-09],\n",
      "          [-2.1808e-10,  1.1508e-08, -2.9958e-09, -1.1077e-08, -7.4530e-09],\n",
      "          [-1.3899e-08, -6.8077e-09, -7.7358e-09, -2.0499e-08, -2.0338e-08],\n",
      "          [ 1.0228e-08,  1.8382e-08, -1.8249e-09,  1.5061e-08, -3.5432e-09],\n",
      "          [-5.8330e-09, -1.0799e-09,  8.2299e-09,  1.1773e-08, -1.8219e-08]],\n",
      "\n",
      "         [[-1.7882e-09,  4.0387e-09, -1.3973e-09, -4.2094e-10, -1.7586e-09],\n",
      "          [-2.8390e-10,  2.8173e-09, -2.5305e-09,  7.8014e-09,  4.9035e-09],\n",
      "          [-8.9539e-09,  3.8617e-09, -4.7940e-10,  1.2326e-09, -3.1911e-09],\n",
      "          [-1.5473e-09,  6.8463e-09,  2.6546e-09,  4.2380e-09,  2.3036e-09],\n",
      "          [-2.2913e-09,  5.8615e-09, -1.0080e-09,  9.1070e-11, -1.3142e-10]],\n",
      "\n",
      "         [[-7.2571e-10, -1.2425e-08, -6.2790e-09,  2.9695e-09,  3.1716e-09],\n",
      "          [-9.3648e-10, -1.2715e-08,  4.4626e-11, -1.9810e-09,  6.9213e-09],\n",
      "          [-7.6706e-09, -5.1896e-09, -3.1034e-09, -3.8777e-09,  7.3826e-09],\n",
      "          [-1.0527e-08, -1.6713e-08,  7.4105e-09, -1.6539e-08, -5.9415e-09],\n",
      "          [ 5.2389e-09,  1.0521e-09,  2.0390e-08, -7.7252e-09,  3.4283e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3468e-09,  2.0638e-10,  1.2709e-09, -1.9357e-09,  6.7445e-10],\n",
      "          [-6.8827e-09, -7.6034e-09,  5.0305e-09,  1.8014e-09,  5.2397e-09],\n",
      "          [ 9.7504e-09,  8.4388e-09, -8.4374e-09,  1.2685e-08,  6.0926e-09],\n",
      "          [ 4.7182e-09,  1.1209e-08,  4.6856e-09, -1.2669e-08,  8.4998e-09],\n",
      "          [ 7.5982e-10,  4.5876e-09,  5.3203e-09,  7.9402e-09,  2.0757e-08]],\n",
      "\n",
      "         [[ 3.7032e-09,  1.7182e-09,  3.3263e-09,  3.5408e-09,  3.8658e-10],\n",
      "          [-4.3531e-09,  1.0463e-09,  1.3677e-09, -2.6582e-09,  5.2849e-09],\n",
      "          [ 3.6264e-09,  3.9415e-09, -8.2629e-09, -4.8992e-09, -3.3334e-09],\n",
      "          [ 1.3775e-09, -1.0297e-09, -3.0737e-10,  2.1560e-09, -3.6903e-10],\n",
      "          [-6.4033e-10,  1.0788e-09,  4.8569e-11,  8.8919e-09, -5.0440e-09]],\n",
      "\n",
      "         [[-8.9214e-09,  1.3171e-09, -7.4846e-09,  3.6068e-09,  2.5900e-09],\n",
      "          [-5.6925e-09,  1.5860e-08, -3.8790e-09,  7.0197e-09, -1.7161e-09],\n",
      "          [-4.2257e-09,  1.1319e-08,  3.4852e-09,  6.5328e-09,  7.0185e-10],\n",
      "          [-1.5813e-08,  1.8611e-08, -9.7000e-09,  5.6064e-09, -6.8024e-09],\n",
      "          [-1.5177e-08,  1.8885e-08, -1.7139e-08,  6.6733e-09,  1.3153e-09]]],\n",
      "\n",
      "\n",
      "        [[[-1.2012e-08, -2.1399e-08,  1.3501e-09, -5.5777e-09, -1.1782e-08],\n",
      "          [ 9.1394e-09, -3.5028e-10,  3.0344e-08, -1.7092e-08, -1.4979e-09],\n",
      "          [-1.5958e-08, -1.4232e-08, -2.7060e-08,  6.3604e-09,  6.2562e-09],\n",
      "          [ 4.5383e-10, -1.6476e-08,  8.3271e-09, -1.1767e-09,  2.3770e-08],\n",
      "          [-1.3221e-08,  1.2338e-08, -2.0939e-09,  2.6974e-08,  1.7250e-09]],\n",
      "\n",
      "         [[-3.4429e-10,  3.7965e-09, -2.9744e-10,  6.8017e-10, -2.2101e-09],\n",
      "          [ 5.2146e-10,  2.3110e-09, -2.5726e-09, -9.8294e-10, -1.9242e-09],\n",
      "          [-5.3866e-09,  7.8759e-09, -3.4378e-09,  9.5900e-10,  9.3778e-11],\n",
      "          [-9.6252e-10,  4.1741e-09,  1.3253e-09, -1.4511e-10,  6.1305e-10],\n",
      "          [-2.9958e-09,  9.2541e-10,  2.7749e-09,  2.6634e-09, -8.5388e-10]],\n",
      "\n",
      "         [[-3.0477e-09, -9.0217e-09, -6.2109e-10,  2.9544e-09,  1.0909e-09],\n",
      "          [-7.4739e-09, -3.9263e-09,  5.9034e-09, -1.2431e-08,  9.5838e-09],\n",
      "          [ 4.6652e-09, -7.4062e-09,  3.8354e-09,  1.9060e-08,  5.5136e-09],\n",
      "          [ 3.8494e-09, -8.5939e-09,  6.3262e-09,  1.5370e-08,  1.3254e-08],\n",
      "          [ 8.8655e-09, -5.8218e-09,  7.4036e-09,  7.1652e-10,  1.5412e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0664e-08,  1.9852e-09,  3.9323e-09,  1.1631e-09, -3.5678e-09],\n",
      "          [-4.6771e-09, -1.9973e-08, -8.4870e-09, -1.1945e-08, -1.0865e-09],\n",
      "          [ 1.1064e-08, -5.3187e-09, -1.0720e-08, -4.4289e-09,  4.8629e-09],\n",
      "          [ 1.0050e-09, -1.4794e-08,  2.9871e-09, -1.4496e-08,  6.3969e-09],\n",
      "          [ 3.6531e-09, -4.8410e-10,  1.0254e-09,  8.6552e-09,  1.4774e-10]],\n",
      "\n",
      "         [[ 1.1300e-09,  1.0880e-08, -2.7246e-10,  3.9568e-09,  6.2829e-10],\n",
      "          [ 5.6758e-09, -1.3270e-09,  3.2663e-09, -6.0927e-09,  4.1633e-09],\n",
      "          [ 3.8290e-09,  7.0162e-09,  1.8965e-09, -1.2674e-10, -1.5497e-11],\n",
      "          [ 6.1865e-09, -3.7555e-10,  8.7248e-10,  8.4369e-09,  6.2359e-09],\n",
      "          [-2.0847e-09,  2.1035e-09, -1.8780e-09, -3.6518e-09,  5.2310e-10]],\n",
      "\n",
      "         [[-1.8220e-09,  1.4459e-08,  8.4664e-09, -9.6435e-09, -2.5922e-09],\n",
      "          [-1.5847e-08,  2.3177e-08, -1.7067e-08,  1.5083e-08, -1.0416e-08],\n",
      "          [ 6.1213e-09, -7.7955e-10,  7.5244e-09,  6.9088e-09, -9.4678e-10],\n",
      "          [-1.1012e-08,  2.4764e-08,  3.4534e-09,  1.9024e-08, -3.5696e-09],\n",
      "          [-8.2592e-09, -6.4655e-09, -9.7468e-10,  3.7995e-09, -1.1543e-08]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.1548e-08, -3.0542e-09, -9.7208e-09, -1.1344e-08, -6.2896e-09],\n",
      "          [-4.0914e-09,  6.4990e-09, -1.3941e-08, -1.3963e-08,  7.1380e-11],\n",
      "          [-9.6223e-09, -4.7167e-08, -2.5481e-08, -4.4167e-08,  7.2676e-09],\n",
      "          [ 2.9384e-09,  6.9989e-09,  4.1548e-09,  1.3911e-08,  2.9783e-09],\n",
      "          [ 1.3702e-08, -7.4829e-09,  5.0607e-09, -3.3425e-08, -1.6847e-08]],\n",
      "\n",
      "         [[ 9.6492e-11,  3.6227e-09, -2.8438e-09,  1.5853e-09, -2.6679e-09],\n",
      "          [-3.1730e-09,  2.0365e-09, -2.9045e-10,  5.8883e-10,  2.8556e-09],\n",
      "          [-7.4589e-09,  3.1734e-09, -1.6154e-09,  1.4920e-09,  2.3174e-09],\n",
      "          [-3.9279e-09, -4.1640e-09, -1.6509e-09,  5.2533e-09, -2.0433e-09],\n",
      "          [-2.0164e-09,  3.8551e-09,  5.1203e-10,  5.8958e-09, -2.0354e-09]],\n",
      "\n",
      "         [[-4.2321e-09, -2.8078e-08,  5.7634e-09,  1.9700e-09,  1.2038e-09],\n",
      "          [-1.2664e-08,  1.6970e-08, -9.3449e-09, -1.1422e-08,  1.6830e-09],\n",
      "          [ 1.0230e-08, -1.3192e-08, -5.7244e-09,  6.5354e-09,  2.7928e-09],\n",
      "          [ 6.8670e-09, -1.3354e-08, -1.4206e-08, -3.6543e-08, -1.6494e-09],\n",
      "          [ 2.1853e-08, -2.5735e-08, -1.1838e-08, -6.7067e-09,  1.0212e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1515e-08,  2.3714e-09, -4.8931e-09,  8.5777e-09, -9.2636e-09],\n",
      "          [ 6.2694e-10, -1.5697e-08, -6.6299e-09, -1.9533e-09,  3.2175e-09],\n",
      "          [-8.7134e-10,  2.5054e-09, -2.2438e-08, -1.6021e-09,  1.6627e-09],\n",
      "          [ 2.2529e-09, -1.5703e-08,  1.1023e-08, -1.2379e-08, -6.2280e-09],\n",
      "          [ 8.4759e-10, -2.1628e-09,  2.7316e-09, -1.0755e-08,  4.2369e-09]],\n",
      "\n",
      "         [[ 3.2104e-09,  1.3457e-09, -6.1437e-09, -1.2323e-10, -1.9642e-09],\n",
      "          [ 3.5101e-10, -3.2971e-09, -3.6276e-09, -8.9164e-10, -1.9132e-09],\n",
      "          [ 5.3188e-09,  1.0595e-08,  1.3480e-09, -8.0415e-09,  2.9258e-09],\n",
      "          [-6.6966e-09,  7.1964e-09, -4.1987e-09, -7.3678e-09, -2.3474e-09],\n",
      "          [ 2.1595e-09,  4.6566e-09, -2.4378e-09,  1.0114e-08,  4.9836e-09]],\n",
      "\n",
      "         [[-1.4672e-08, -1.2798e-09,  2.2938e-09,  4.5868e-09,  4.4455e-09],\n",
      "          [ 1.0200e-08,  7.2292e-09, -5.0344e-09,  2.5271e-08,  1.4176e-08],\n",
      "          [-2.0812e-08,  1.2974e-08,  4.5423e-09,  1.3792e-08, -1.7976e-08],\n",
      "          [-1.1845e-08,  5.7753e-09, -3.3486e-09,  1.2439e-08,  8.6197e-09],\n",
      "          [ 1.3205e-09,  1.2616e-08, -1.9359e-09,  4.9302e-09, -1.5289e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4435e-09,  1.5530e-08, -1.0866e-08,  1.9567e-09,  2.2812e-10],\n",
      "          [ 8.8254e-09, -4.8777e-09,  1.5259e-08, -5.9674e-09,  2.1471e-08],\n",
      "          [ 4.4364e-09,  6.4229e-09,  1.1571e-10,  1.4905e-10, -2.8076e-09],\n",
      "          [ 3.4163e-09, -4.3997e-09,  2.2734e-08, -4.4281e-09,  1.1258e-08],\n",
      "          [-3.6709e-09,  1.8733e-08, -1.1469e-08, -6.4929e-09, -5.7963e-09]],\n",
      "\n",
      "         [[-6.7439e-09,  4.5358e-10, -1.2464e-09,  1.8186e-09, -1.2991e-09],\n",
      "          [ 6.0728e-09, -1.8623e-09, -1.2240e-09,  1.6875e-09, -2.3207e-09],\n",
      "          [-3.7053e-09,  2.1559e-09, -2.4227e-09,  2.4877e-09,  3.0818e-10],\n",
      "          [-1.7382e-09,  1.8331e-09, -1.7472e-09,  3.6855e-09, -6.7771e-10],\n",
      "          [-9.9616e-10,  2.2549e-09, -8.2741e-10,  2.5359e-09,  1.4885e-09]],\n",
      "\n",
      "         [[ 5.6127e-09, -1.3738e-08, -1.2015e-09, -5.3409e-09, -3.8419e-09],\n",
      "          [-2.1966e-09, -1.1134e-09, -2.6077e-09, -1.5253e-08,  8.8557e-09],\n",
      "          [ 1.0437e-08, -1.3951e-08,  1.4268e-08,  5.8836e-09,  1.1540e-08],\n",
      "          [ 1.0406e-08, -2.1838e-09,  2.3028e-08, -3.5284e-09,  7.9381e-09],\n",
      "          [ 9.7480e-09, -9.0401e-10,  4.2318e-09, -5.3238e-09,  8.6965e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.2255e-09, -2.6237e-09,  6.3966e-09, -2.6931e-09,  6.3230e-09],\n",
      "          [-9.4553e-10, -1.9325e-08, -4.5884e-09, -3.5104e-08, -4.4776e-09],\n",
      "          [ 2.9968e-09,  8.1478e-09, -2.0899e-09, -4.1994e-10,  1.6625e-09],\n",
      "          [-4.2026e-09, -4.6096e-09,  1.0893e-08, -6.5580e-09,  5.1809e-09],\n",
      "          [ 1.3687e-09, -1.0060e-08, -6.6241e-09,  8.8708e-09,  3.3774e-09]],\n",
      "\n",
      "         [[ 6.8038e-09, -2.0451e-09, -5.1718e-09,  3.7196e-09, -1.8969e-10],\n",
      "          [ 1.1564e-09, -5.9751e-09,  5.6856e-10, -4.1223e-09,  2.2576e-09],\n",
      "          [-2.5706e-09,  7.0700e-09,  1.6266e-09, -5.5857e-09,  2.5683e-10],\n",
      "          [-4.5971e-10, -1.6047e-11,  1.0567e-08,  5.9186e-10,  1.1713e-08],\n",
      "          [ 1.6089e-09,  3.7795e-09,  1.8617e-09,  3.4218e-10,  2.4483e-09]],\n",
      "\n",
      "         [[ 3.1320e-09,  1.7255e-08, -3.3681e-09,  2.4624e-09,  3.5032e-10],\n",
      "          [-5.0493e-09,  1.5845e-09, -5.6575e-09,  1.2676e-08, -8.3860e-09],\n",
      "          [-9.5177e-09,  5.2326e-09,  6.1183e-09, -3.5877e-09,  4.3871e-11],\n",
      "          [ 1.6173e-09,  1.1311e-08, -3.1536e-09,  1.0346e-08, -2.6204e-09],\n",
      "          [-6.5180e-09, -6.5128e-09,  5.6669e-09, -1.6894e-09, -1.3283e-08]]],\n",
      "\n",
      "\n",
      "        [[[-9.7057e-09, -1.2876e-08,  3.8034e-10, -2.5978e-08, -6.9606e-11],\n",
      "          [ 4.6708e-09, -5.3641e-09,  3.2063e-10,  1.1716e-08,  1.0537e-08],\n",
      "          [ 7.3250e-09,  6.6084e-09, -1.8149e-08,  1.6128e-08, -5.7245e-09],\n",
      "          [ 9.7060e-09,  5.3335e-09,  1.2453e-08, -1.7160e-08,  1.2682e-08],\n",
      "          [-2.7555e-09,  1.2995e-08, -5.2420e-09,  3.1693e-09, -6.4117e-09]],\n",
      "\n",
      "         [[-2.6617e-09,  2.9259e-09,  5.8303e-10, -4.2444e-10,  1.7888e-11],\n",
      "          [ 1.0367e-11, -3.3194e-09,  4.3095e-09,  6.9482e-09, -2.4631e-09],\n",
      "          [-3.6008e-10,  3.3623e-09, -3.2949e-09,  2.9419e-09, -4.9348e-09],\n",
      "          [-4.0159e-09,  3.1967e-09,  6.6387e-10, -3.0264e-09,  3.8291e-09],\n",
      "          [-6.7569e-10,  2.4258e-09, -5.8392e-10, -2.0857e-09,  2.0386e-09]],\n",
      "\n",
      "         [[ 3.3919e-09, -1.0614e-08,  9.6240e-10, -1.2300e-08, -2.0171e-09],\n",
      "          [-3.3410e-09, -1.6881e-08, -9.2010e-09,  1.1536e-09, -4.5187e-09],\n",
      "          [ 1.1741e-08, -1.2835e-08,  1.2816e-09, -5.8529e-09, -2.3957e-09],\n",
      "          [ 9.4932e-11, -1.6309e-08,  2.7061e-08, -1.9243e-08,  1.2333e-08],\n",
      "          [ 1.5384e-08,  1.1699e-08,  3.7621e-09, -2.2676e-08,  9.0340e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.2300e-10, -1.0779e-08,  7.9464e-09,  5.2679e-09, -5.0461e-10],\n",
      "          [ 1.5714e-09, -1.1209e-09, -3.6302e-10,  9.3375e-09,  2.1102e-09],\n",
      "          [-8.3446e-11, -4.6424e-09,  3.3219e-09, -7.5509e-10,  3.4948e-09],\n",
      "          [ 9.0230e-10,  4.4617e-09,  9.5071e-09, -3.8928e-09,  5.9999e-09],\n",
      "          [-4.8181e-10,  1.0436e-08, -7.9474e-10, -3.6892e-09,  3.2778e-09]],\n",
      "\n",
      "         [[ 5.5046e-09,  4.9114e-09,  4.7378e-09,  1.7185e-09,  6.6228e-10],\n",
      "          [-3.8091e-09,  2.6687e-09,  7.2153e-09, -4.3441e-09,  4.4875e-09],\n",
      "          [ 2.4764e-09,  2.4351e-09,  1.1302e-08,  1.4632e-09,  6.5547e-09],\n",
      "          [ 5.9981e-09,  4.4253e-10,  2.4750e-09,  4.7109e-09,  5.5943e-09],\n",
      "          [ 2.9601e-09, -7.7578e-09,  6.9322e-09,  1.2988e-09,  1.7765e-09]],\n",
      "\n",
      "         [[-5.1678e-09, -9.2991e-11,  1.0066e-08,  6.1724e-09, -8.2287e-10],\n",
      "          [-2.5976e-09,  1.8997e-10, -2.8681e-09,  6.9729e-09, -4.2048e-09],\n",
      "          [-3.4555e-09, -2.5752e-09, -4.4274e-09,  1.0643e-08,  4.5739e-09],\n",
      "          [-1.9387e-08,  2.1217e-08, -1.5578e-08,  3.9238e-09, -5.1727e-09],\n",
      "          [-6.4959e-09, -1.3532e-09, -5.1038e-09,  6.4629e-10, -1.3976e-08]]]],\n",
      "       device='cuda:0')\n",
      "tensor([ 6.5045e-10,  3.9561e-08, -2.7634e-08,  3.5243e-08,  1.2039e-08,\n",
      "         3.1177e-08, -1.3672e-09,  1.0776e-08, -3.1123e-09,  3.0196e-08,\n",
      "         6.1698e-09, -5.7985e-08,  2.6882e-08, -6.3033e-09,  2.7839e-08,\n",
      "         1.6149e-08,  2.4940e-08,  4.1149e-08, -1.0633e-08, -2.4752e-08,\n",
      "        -3.6740e-09,  4.4873e-08,  2.5109e-08, -1.4426e-09,  2.6341e-08,\n",
      "        -2.0191e-08, -5.1763e-10, -7.9667e-08, -1.0940e-08,  5.1918e-08,\n",
      "         6.0912e-08, -3.3402e-09,  1.3800e-08,  1.4053e-08, -9.5215e-09,\n",
      "         1.5099e-08,  1.2252e-08,  5.9397e-08,  8.6232e-09,  1.0930e-08,\n",
      "        -5.4344e-09, -1.5654e-09,  3.2690e-08,  3.3617e-08, -2.8619e-08,\n",
      "         2.5539e-08, -1.1266e-08,  2.4267e-08, -4.3445e-08,  5.3184e-08,\n",
      "         1.3635e-08,  2.3471e-08,  2.1293e-08,  1.6411e-08,  2.9490e-09,\n",
      "         1.0671e-08, -2.6593e-08, -6.2553e-08, -4.3327e-08, -5.3852e-08,\n",
      "         1.0789e-08, -4.8884e-08, -1.0932e-07,  2.6064e-08,  7.0785e-09,\n",
      "        -5.4980e-10,  3.2396e-08,  3.2181e-09, -5.8133e-08,  2.6710e-08,\n",
      "        -8.5262e-09, -1.3412e-08,  5.6447e-08,  1.6492e-08, -9.3303e-09,\n",
      "        -3.2700e-08,  2.9509e-09, -2.5820e-08,  9.9756e-09,  4.4930e-08,\n",
      "        -1.4068e-08,  1.7852e-08, -5.4848e-08,  1.7625e-08, -3.8735e-08,\n",
      "        -6.1728e-08,  3.3693e-09, -1.3276e-08, -1.7830e-09,  2.8133e-08,\n",
      "        -2.2862e-08,  2.3578e-08,  4.2380e-08, -3.3220e-08,  2.1392e-08,\n",
      "         4.2809e-08,  2.7655e-09,  1.5274e-09,  2.0778e-08,  1.6928e-08,\n",
      "        -2.7196e-08, -3.8032e-08, -4.6362e-10, -3.4951e-08,  2.2232e-08,\n",
      "         4.3631e-08, -3.7167e-09,  4.1906e-08, -6.7364e-09, -1.1615e-08,\n",
      "        -9.6371e-09, -1.5529e-09,  2.7512e-09, -5.9219e-08,  8.6720e-08,\n",
      "        -3.3113e-08,  1.6164e-08,  9.6635e-10, -1.0463e-07,  5.0681e-09,\n",
      "        -1.1073e-08,  1.5060e-09, -3.9598e-08, -1.9459e-08, -7.6767e-08,\n",
      "        -7.4475e-08, -3.9681e-08, -1.9477e-08, -3.0938e-08, -3.0035e-08,\n",
      "         4.6088e-08,  6.6638e-08,  4.4282e-08, -1.1840e-08, -3.9454e-08,\n",
      "        -1.4094e-08, -1.9309e-08,  2.4794e-08,  8.0768e-09,  4.1306e-08,\n",
      "         2.3068e-08,  8.6621e-09, -3.8754e-08, -2.5206e-08, -2.7253e-08,\n",
      "        -2.5039e-09, -4.2929e-08,  5.8142e-08, -6.4936e-08, -2.5443e-08,\n",
      "         6.6895e-08, -2.9696e-08, -2.2344e-08, -2.4219e-08,  3.7384e-08,\n",
      "         8.5739e-08, -2.8672e-08, -3.2880e-08, -3.0074e-09,  6.3204e-09,\n",
      "        -7.1758e-09,  7.8293e-08,  1.2345e-08, -1.5385e-08, -3.7780e-08,\n",
      "        -3.6325e-08,  7.6213e-09,  2.2544e-08, -2.2376e-08, -2.1441e-09,\n",
      "         8.4744e-09, -2.1090e-08,  3.9356e-08, -3.7593e-09,  1.9270e-08,\n",
      "         2.7681e-08, -1.5535e-08,  1.1765e-08, -4.5397e-08, -3.2040e-09,\n",
      "        -1.1428e-09,  3.7556e-08, -3.3666e-08, -3.8654e-08,  1.9840e-08,\n",
      "         8.6525e-09, -4.8803e-08,  2.5669e-08,  3.0737e-08, -4.5035e-09,\n",
      "         1.1259e-08,  2.0944e-08,  1.2735e-08,  3.7319e-08, -5.2510e-08,\n",
      "         2.1093e-08,  9.1394e-09, -1.4539e-08, -9.3045e-09, -3.8860e-09,\n",
      "         1.1071e-08, -6.6250e-09,  3.3161e-09, -1.8321e-09, -1.9420e-08,\n",
      "         1.8593e-08,  2.6091e-10,  6.3957e-08, -3.5155e-09, -2.4638e-08,\n",
      "         1.0670e-08,  1.3486e-08,  4.4703e-09, -1.7973e-10,  2.6111e-09,\n",
      "         5.6399e-08, -1.2525e-08,  3.9348e-09,  2.1240e-08, -7.6755e-10,\n",
      "         1.7227e-08,  4.5662e-08,  6.9698e-08,  3.6618e-08, -8.3288e-09,\n",
      "         1.1093e-08, -1.9316e-08,  4.1234e-08,  2.5935e-08, -3.2031e-09,\n",
      "         2.7940e-08, -9.9416e-10,  2.3238e-08,  2.7426e-08,  1.6717e-08,\n",
      "        -1.5926e-08,  1.4519e-08,  6.0792e-09, -2.3927e-08, -4.4984e-08,\n",
      "        -2.0647e-08,  7.1936e-08,  7.9320e-08, -1.7200e-08, -4.1812e-08,\n",
      "        -2.0909e-09,  9.7000e-09, -4.9488e-08, -5.5501e-09,  1.2710e-08,\n",
      "        -1.1548e-08, -2.1483e-08, -1.5934e-08, -4.4940e-09, -1.3754e-08,\n",
      "         1.7202e-09], device='cuda:0')\n",
      "tensor([ 4.7097e-09,  3.9126e-08, -3.9658e-08,  3.3959e-08,  3.7003e-08,\n",
      "         3.0992e-08, -1.9668e-09,  8.5615e-09, -4.2170e-09,  3.0045e-08,\n",
      "         1.9669e-08, -3.7898e-08,  2.3849e-08, -6.3630e-09,  1.8738e-08,\n",
      "         1.0682e-08,  3.9353e-08,  5.7940e-08, -1.7129e-08, -3.3741e-08,\n",
      "        -5.3308e-11,  4.8317e-08,  3.8869e-08,  3.3062e-09,  2.6891e-08,\n",
      "        -1.3972e-08,  1.4865e-08, -8.7449e-08, -5.9724e-09,  5.8076e-08,\n",
      "         7.1745e-08,  6.8057e-09,  1.3162e-08,  9.5320e-09, -1.3486e-08,\n",
      "         1.8280e-08,  1.6536e-08,  7.0853e-08,  1.5406e-08,  1.0121e-08,\n",
      "        -1.2260e-08,  1.4141e-08,  5.4146e-08,  4.2659e-08, -3.9054e-08,\n",
      "         1.0904e-08,  9.9491e-09,  2.7401e-08, -3.9947e-08,  5.0283e-08,\n",
      "         6.0437e-09,  2.9136e-08,  2.9335e-08,  2.9221e-08,  4.3457e-09,\n",
      "         5.7977e-09, -3.7559e-08, -6.3285e-08, -5.7624e-08, -6.0374e-08,\n",
      "         2.3104e-08, -4.5035e-08, -1.4050e-07,  2.6582e-08,  2.2794e-08,\n",
      "        -4.1098e-09,  4.9112e-08, -4.8474e-09, -5.7326e-08,  3.9518e-08,\n",
      "         5.9353e-09, -1.2258e-08,  6.7338e-08,  9.2155e-09, -8.2736e-09,\n",
      "        -2.9433e-08,  1.4338e-08, -3.6258e-08,  2.9171e-08,  4.6707e-08,\n",
      "        -5.2043e-09,  2.9100e-08, -6.3826e-08,  1.9416e-08, -3.7844e-08,\n",
      "        -7.7608e-08, -4.4680e-09, -6.7280e-09, -6.8274e-09,  3.0534e-08,\n",
      "        -1.7342e-08,  5.3699e-08,  5.1764e-08, -5.6044e-08,  4.8864e-08,\n",
      "         4.9497e-08, -1.5005e-08,  1.0255e-08,  2.0005e-08,  2.5258e-08,\n",
      "        -1.2339e-08, -3.4156e-08, -1.0848e-08, -4.9040e-08,  3.1990e-08,\n",
      "         5.7078e-08, -3.8205e-09,  4.6868e-08,  3.8057e-09, -1.4458e-08,\n",
      "        -2.7812e-09, -3.1352e-09,  2.3374e-08, -5.8277e-08,  1.1221e-07,\n",
      "        -4.4873e-08,  1.0965e-08,  2.2655e-08, -9.6393e-08, -1.1893e-08,\n",
      "        -2.3313e-08, -1.4551e-08, -3.9326e-08, -4.0535e-08, -7.1581e-08,\n",
      "        -5.3079e-08, -4.0261e-08, -1.5214e-08, -3.5450e-08, -5.2584e-08,\n",
      "         3.2826e-08,  9.5450e-08,  4.3178e-08, -1.0319e-08, -3.7781e-08,\n",
      "         4.0339e-09, -3.3431e-08,  2.7308e-08,  8.2592e-09,  4.3838e-08,\n",
      "         7.8289e-09,  1.5175e-08, -4.0473e-08, -4.1266e-08, -2.8516e-08,\n",
      "         1.3861e-08, -4.1627e-08,  6.6693e-08, -4.4680e-08, -2.9447e-08,\n",
      "         7.5242e-08, -5.5774e-08, -2.0758e-08, -2.6513e-08,  4.2378e-08,\n",
      "         7.9720e-08, -2.2645e-08, -3.2203e-08, -1.1123e-08,  7.4667e-10,\n",
      "        -1.1949e-08,  8.2123e-08,  2.0965e-08, -1.4602e-08, -6.2025e-08,\n",
      "        -6.5930e-08, -4.8267e-09,  2.6834e-08, -1.5760e-09, -1.5463e-08,\n",
      "         1.6576e-08, -2.8828e-08,  5.1235e-08, -1.1758e-08,  2.8648e-08,\n",
      "         4.3550e-08, -9.1041e-09,  2.9639e-08, -4.7391e-08, -5.9799e-09,\n",
      "        -6.1905e-09,  3.5890e-08, -4.2041e-08, -4.3719e-08,  2.5601e-08,\n",
      "        -3.0981e-10, -4.9600e-08,  2.7408e-08,  5.3062e-08, -1.4894e-08,\n",
      "        -2.6891e-09,  1.3395e-08,  3.7831e-09,  4.3517e-08, -4.0094e-08,\n",
      "         2.6758e-08,  5.5933e-09, -2.0640e-08,  1.1725e-08,  1.1781e-08,\n",
      "         3.8350e-09,  6.7499e-09, -5.4408e-10, -6.9330e-09, -3.6781e-08,\n",
      "        -8.8455e-10, -4.1768e-09,  6.3991e-08,  1.5615e-08, -3.4383e-08,\n",
      "         1.1983e-08,  2.1171e-08,  1.4341e-08, -2.0709e-08,  2.4669e-08,\n",
      "         9.2179e-08, -2.0970e-08, -1.3364e-09,  1.3399e-08,  8.4550e-09,\n",
      "         1.7029e-08,  5.3337e-08,  5.6682e-08,  3.7406e-08, -1.0163e-08,\n",
      "         2.5407e-08, -1.1231e-08,  5.7699e-08,  2.8731e-08, -1.3047e-08,\n",
      "         3.7559e-08, -5.2779e-10,  1.2232e-08,  3.3180e-08,  2.6284e-08,\n",
      "        -2.3464e-08,  2.1815e-08,  3.1497e-09, -1.3645e-08, -6.0028e-08,\n",
      "        -2.6843e-08,  7.4597e-08,  9.7511e-08, -2.2149e-08, -5.4470e-08,\n",
      "         3.3791e-09,  1.4122e-08, -3.7418e-08,  1.8446e-08,  1.7867e-08,\n",
      "         2.3125e-09, -3.3140e-08, -1.3736e-08, -9.0728e-09, -2.1932e-08,\n",
      "        -1.9996e-08], device='cuda:0')\n",
      "tensor([[[[-2.5762e-09,  4.9010e-09, -6.0410e-10,  5.5364e-09,  6.3401e-10],\n",
      "          [ 1.2869e-09, -6.0063e-09,  2.4002e-09, -6.8101e-09,  2.0323e-09],\n",
      "          [ 1.6912e-09,  2.9036e-09,  3.1384e-09,  5.2090e-09,  3.7141e-09],\n",
      "          [ 1.7998e-11, -4.8662e-09,  7.7664e-10, -5.8391e-09, -2.8294e-09],\n",
      "          [ 1.7085e-09,  3.4855e-09, -5.5648e-10,  4.4149e-09,  7.2283e-11]],\n",
      "\n",
      "         [[-3.7359e-09,  2.3355e-08,  2.2816e-09,  2.1975e-08, -3.4595e-08],\n",
      "          [-4.8229e-08,  7.7162e-08, -4.4481e-08,  3.7309e-08, -4.7024e-08],\n",
      "          [-1.7023e-08, -2.9475e-09,  6.5403e-10, -2.1075e-09, -1.9749e-08],\n",
      "          [-3.6542e-08,  4.5772e-08, -3.1854e-08,  4.2861e-08, -5.1362e-08],\n",
      "          [ 1.1509e-08,  1.8171e-08, -2.1488e-09,  1.1657e-08, -6.7915e-09]],\n",
      "\n",
      "         [[ 2.2431e-08,  2.1088e-08,  4.6409e-08, -1.7613e-09,  6.3076e-08],\n",
      "          [-7.8566e-09, -1.7759e-08, -1.9714e-09, -3.0595e-10, -1.8433e-08],\n",
      "          [ 3.7609e-08,  1.3309e-08,  5.4581e-08,  1.7333e-08,  4.0751e-08],\n",
      "          [ 1.0232e-08, -1.6911e-08,  6.8619e-09, -6.3557e-09, -4.8045e-08],\n",
      "          [ 4.0269e-08,  1.3582e-08,  4.4371e-08,  1.5484e-09,  8.4665e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8500e-09,  7.0890e-09, -8.8420e-10,  6.9457e-09, -2.1588e-09],\n",
      "          [-3.3018e-09,  1.0221e-10, -5.1294e-09, -6.1216e-10, -1.4552e-09],\n",
      "          [-8.7880e-10,  7.5156e-09, -4.8818e-10,  3.6875e-09, -2.6322e-10],\n",
      "          [-1.1867e-09, -2.3770e-10, -3.4254e-09, -3.8446e-10, -3.4144e-09],\n",
      "          [-1.3953e-09,  2.6656e-09, -1.0083e-09,  4.6458e-09, -9.6042e-10]],\n",
      "\n",
      "         [[-8.9534e-08,  9.2340e-08, -1.2544e-07,  1.0276e-07, -1.1166e-07],\n",
      "          [-5.2267e-08,  5.2131e-08, -3.0383e-08,  5.9171e-08, -3.1473e-08],\n",
      "          [-1.3884e-07,  8.1242e-08, -1.7121e-07,  7.7547e-08, -1.3522e-07],\n",
      "          [-1.2505e-08,  5.0515e-08, -2.4358e-08,  6.4238e-08,  9.2458e-09],\n",
      "          [-1.0408e-07,  7.5367e-08, -1.1217e-07,  4.0685e-08, -7.9799e-08]],\n",
      "\n",
      "         [[ 2.1483e-08, -1.3740e-08,  2.2879e-08, -8.2975e-09,  2.1149e-08],\n",
      "          [ 5.0045e-09, -1.5047e-09, -2.8529e-09, -1.6670e-10, -1.7479e-09],\n",
      "          [ 1.1381e-08, -1.0089e-08,  1.7449e-08, -1.2624e-08,  1.4645e-08],\n",
      "          [-6.0983e-09, -7.9687e-09, -4.3368e-09, -8.4653e-10, -6.0524e-09],\n",
      "          [ 1.1787e-08, -7.4684e-09,  2.1838e-08, -1.6619e-08,  1.0443e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8470e-11,  1.3260e-09,  5.4230e-10,  1.1838e-09,  3.7876e-11],\n",
      "          [ 9.5464e-10, -1.4861e-09,  4.8239e-10, -1.9915e-09,  5.7539e-10],\n",
      "          [-8.0078e-11,  6.0782e-10, -3.4213e-10,  1.3663e-09,  1.2399e-10],\n",
      "          [ 7.2877e-10, -2.6860e-09,  6.3596e-10, -2.1800e-09, -3.9264e-10],\n",
      "          [ 4.6434e-10,  1.1947e-09,  3.8138e-10,  1.7095e-09,  5.0559e-10]],\n",
      "\n",
      "         [[-9.6100e-10,  6.1524e-09,  6.6584e-09, -1.3134e-09, -5.7230e-09],\n",
      "          [-7.9621e-09,  1.9805e-08, -1.0671e-08,  1.3282e-08, -1.3252e-08],\n",
      "          [-1.6638e-09,  2.8314e-09,  3.6093e-09, -1.9823e-09, -5.9199e-09],\n",
      "          [-1.5055e-08,  1.4569e-08, -1.0935e-08,  1.7524e-08, -1.2957e-08],\n",
      "          [ 1.1522e-09,  2.0739e-09, -3.6255e-09, -8.6041e-10,  2.5967e-09]],\n",
      "\n",
      "         [[ 8.7589e-09,  5.5586e-09,  3.3987e-09,  1.8303e-09,  8.7893e-09],\n",
      "          [-1.0259e-08, -9.0747e-09, -1.3103e-08, -1.0145e-08, -7.4278e-09],\n",
      "          [ 4.3491e-09,  1.5993e-09,  1.2157e-08,  2.1000e-09,  2.5909e-09],\n",
      "          [-4.5893e-09, -2.3468e-09, -5.5012e-09,  1.2742e-09, -6.9648e-09],\n",
      "          [ 1.9597e-08,  5.6949e-09,  1.8503e-08,  4.2703e-09,  1.7122e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.1198e-10,  1.4044e-09, -4.8246e-10,  6.0158e-10, -2.2365e-10],\n",
      "          [-8.1698e-10, -1.4519e-10, -1.2261e-09, -2.6944e-10, -4.0511e-10],\n",
      "          [-9.3654e-10,  1.2678e-09, -4.0004e-10,  1.3740e-09, -5.9701e-10],\n",
      "          [-8.3232e-12, -1.3966e-10, -1.2123e-09, -1.2985e-10, -5.4345e-10],\n",
      "          [-5.3900e-10,  1.2552e-09, -7.5181e-10,  1.9957e-09,  1.1119e-10]],\n",
      "\n",
      "         [[-3.2097e-08,  2.7168e-08, -2.9815e-08,  1.7688e-08, -2.1097e-08],\n",
      "          [-1.6407e-08,  9.4541e-09, -8.8953e-09,  1.4796e-08, -9.7214e-09],\n",
      "          [-2.5242e-08,  2.5921e-08, -1.6657e-08,  2.9427e-08, -4.2958e-08],\n",
      "          [-2.0075e-08,  1.4631e-08, -1.0653e-08,  1.1187e-08, -3.3223e-09],\n",
      "          [-2.4023e-08,  2.6831e-08, -3.5578e-08,  3.4974e-08, -3.0886e-08]],\n",
      "\n",
      "         [[ 3.6870e-09, -1.0484e-09,  5.0644e-09, -1.4034e-09,  6.0767e-09],\n",
      "          [ 1.6841e-10, -2.0860e-10, -1.4281e-10, -5.8686e-10, -1.0900e-09],\n",
      "          [ 7.1477e-09, -4.4482e-09,  4.7900e-09, -4.1497e-09,  6.3788e-09],\n",
      "          [-2.1506e-09, -9.1017e-10, -4.6880e-09,  5.2844e-10, -9.7487e-10],\n",
      "          [ 4.7230e-09, -2.8279e-09,  4.7210e-09, -2.5815e-09,  4.2993e-09]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7899e-09,  5.0991e-09, -1.7016e-09,  2.3979e-09, -1.7101e-09],\n",
      "          [ 1.5967e-10, -6.8977e-09,  2.1568e-09, -6.2262e-09,  1.4039e-10],\n",
      "          [-1.4456e-09,  3.1446e-09,  2.9740e-09,  2.4543e-09,  1.8226e-10],\n",
      "          [ 2.2898e-09, -6.9796e-09,  1.8805e-09, -6.7449e-09,  1.7698e-09],\n",
      "          [ 1.4486e-09,  4.9054e-09,  2.4129e-09,  1.0286e-09, -8.6043e-10]],\n",
      "\n",
      "         [[-1.6711e-08,  6.9166e-11, -1.4640e-08, -4.6684e-09, -2.1722e-08],\n",
      "          [-2.6103e-08,  3.8724e-08, -3.9050e-08,  3.2117e-08, -4.9773e-08],\n",
      "          [-7.3042e-09,  3.6807e-10, -1.9485e-08,  1.1758e-08, -9.0409e-09],\n",
      "          [-2.9805e-08,  5.1021e-08, -3.0421e-08,  2.0826e-08, -1.8849e-08],\n",
      "          [-1.0990e-08, -6.0159e-09,  2.6877e-09, -4.7973e-09, -7.1000e-09]],\n",
      "\n",
      "         [[ 5.0420e-08,  1.4119e-08,  4.1835e-08,  5.9185e-09,  4.0753e-08],\n",
      "          [-7.4049e-09, -1.9794e-10, -3.2077e-08,  4.9393e-09, -1.7145e-08],\n",
      "          [ 4.4699e-08, -2.8889e-09,  4.7086e-08, -3.8246e-09, -9.8230e-09],\n",
      "          [-2.7257e-08,  7.2853e-09, -2.1817e-08,  1.1937e-08, -1.2221e-08],\n",
      "          [ 8.5474e-08,  1.3393e-08,  5.2043e-08,  4.2926e-09,  5.0419e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.8891e-10,  2.3446e-09, -1.5732e-09,  3.9994e-09, -8.5920e-10],\n",
      "          [-2.4786e-09, -4.5271e-10, -1.9979e-09, -6.7507e-10, -2.3210e-10],\n",
      "          [-3.9503e-10,  3.6195e-09, -6.5997e-10,  3.5495e-09,  2.3124e-11],\n",
      "          [-4.8049e-10, -3.0141e-10, -3.6371e-09,  3.4796e-10, -2.2784e-09],\n",
      "          [-1.4593e-09,  3.8885e-09, -1.1632e-09,  4.0175e-09, -1.7249e-09]],\n",
      "\n",
      "         [[-8.6243e-08,  6.2413e-08, -9.6514e-08,  8.3000e-08, -5.8111e-08],\n",
      "          [-1.7267e-08,  5.6168e-08, -8.2772e-09,  4.0401e-08, -2.4475e-08],\n",
      "          [-9.4722e-08,  4.9147e-08, -1.1223e-07,  8.3737e-08, -7.0191e-08],\n",
      "          [-2.9431e-08,  2.0103e-08, -8.5949e-09,  2.1299e-08,  6.2109e-09],\n",
      "          [-7.6307e-08,  8.7499e-08, -9.5798e-08,  7.1265e-08, -4.8320e-08]],\n",
      "\n",
      "         [[ 1.2792e-08, -9.8613e-09,  1.3375e-08, -8.5839e-09,  5.1926e-09],\n",
      "          [-5.1428e-09, -3.1477e-10, -5.7059e-09, -6.9846e-09, -7.9838e-09],\n",
      "          [ 1.9535e-08, -1.1459e-08,  1.9453e-08, -1.0277e-08,  1.3841e-08],\n",
      "          [-1.2136e-08,  1.3362e-09, -5.5492e-09, -4.3002e-10, -8.8407e-09],\n",
      "          [ 1.0483e-08, -7.9012e-09,  1.1857e-08, -9.9135e-09,  1.2765e-08]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-7.5844e-10,  2.0577e-09, -1.6702e-09,  3.4719e-09, -1.8354e-09],\n",
      "          [-7.1254e-10, -2.7776e-09, -2.3674e-10, -7.9044e-09,  3.8094e-10],\n",
      "          [-4.8670e-10,  1.4561e-09, -3.3605e-09,  2.2958e-09, -4.3923e-10],\n",
      "          [-2.3066e-09, -4.8017e-09, -7.2040e-10, -6.8394e-09, -1.6333e-09],\n",
      "          [-2.4872e-10,  3.5549e-09,  2.3764e-09,  5.6099e-09,  2.4175e-10]],\n",
      "\n",
      "         [[-3.8123e-09, -5.4604e-09, -1.2664e-08,  1.6149e-08, -4.7696e-09],\n",
      "          [-2.5666e-08,  6.1097e-08, -4.6822e-08,  5.0413e-08, -4.0747e-08],\n",
      "          [-4.2515e-09,  8.1431e-09, -1.1272e-08,  3.5084e-09, -2.8872e-08],\n",
      "          [-3.2295e-08,  3.4849e-08, -3.2764e-08,  5.3561e-08, -3.3601e-08],\n",
      "          [-1.7592e-08,  6.3338e-10, -7.6672e-10,  6.1889e-09, -6.9291e-09]],\n",
      "\n",
      "         [[ 5.3021e-08,  1.4165e-08,  2.3199e-08,  1.2191e-08,  4.8042e-08],\n",
      "          [ 4.0492e-09, -3.3464e-08, -2.4478e-08,  4.3651e-09, -2.0475e-08],\n",
      "          [ 4.1721e-08,  7.9985e-09,  1.6920e-08,  1.0902e-08,  2.5482e-08],\n",
      "          [-7.9332e-09, -1.2625e-08, -1.0791e-08, -1.2891e-09, -1.1281e-08],\n",
      "          [ 3.6251e-08,  1.6170e-08,  6.8947e-08,  8.8653e-09,  7.4941e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2553e-09,  2.1771e-09, -4.0022e-10,  3.4850e-09, -1.0952e-09],\n",
      "          [-2.7802e-09, -5.9968e-11, -3.5524e-09, -2.4003e-10, -9.4418e-10],\n",
      "          [-1.2731e-09,  1.7193e-09, -2.6440e-09,  3.8766e-09, -6.9998e-10],\n",
      "          [-2.6082e-09, -4.7930e-10, -3.1496e-09, -2.3296e-10, -1.3685e-09],\n",
      "          [-2.0988e-09,  2.4143e-09, -3.1084e-10,  2.5777e-09, -1.2873e-09]],\n",
      "\n",
      "         [[-6.7821e-08,  7.1934e-08, -5.4143e-08,  5.7570e-08, -6.5291e-08],\n",
      "          [-1.1760e-08,  1.9889e-08, -2.2543e-08,  6.0351e-08, -8.1508e-09],\n",
      "          [-7.3302e-08,  9.4528e-08, -1.2899e-07,  6.5184e-08, -7.2463e-08],\n",
      "          [-3.2036e-08,  6.2777e-08, -3.6607e-08,  2.1560e-08, -4.7003e-09],\n",
      "          [-5.9699e-08,  9.1703e-08, -8.5592e-08,  1.0075e-07, -8.1202e-08]],\n",
      "\n",
      "         [[ 3.5054e-09, -1.1672e-08,  1.2578e-08, -5.6818e-09,  2.9517e-09],\n",
      "          [ 3.1467e-10,  1.4850e-09, -3.0168e-09, -2.8186e-09,  4.1214e-09],\n",
      "          [ 1.4228e-08, -8.2466e-09,  9.9559e-09, -1.2817e-08,  1.5732e-08],\n",
      "          [-7.8187e-09, -6.2055e-09,  1.7297e-09, -3.7827e-09, -5.9500e-09],\n",
      "          [ 6.0994e-09, -1.2555e-08,  1.4433e-08, -1.0237e-08,  1.0253e-08]]],\n",
      "\n",
      "\n",
      "        [[[-7.4580e-10,  1.3910e-09, -3.4821e-10,  1.3453e-09, -3.8202e-10],\n",
      "          [-9.4952e-12, -2.7293e-09,  6.2644e-10, -2.7931e-09, -1.5915e-09],\n",
      "          [ 1.3177e-09,  1.5826e-09,  1.7522e-09,  2.5518e-09,  1.6185e-09],\n",
      "          [ 2.4832e-10, -1.5689e-09, -1.8185e-11, -2.9429e-09, -5.1861e-10],\n",
      "          [-2.3145e-10,  9.5767e-10,  5.1279e-10,  1.6289e-09,  3.9955e-10]],\n",
      "\n",
      "         [[-8.3271e-09,  3.1203e-09, -2.2232e-09, -1.3773e-09, -1.6644e-08],\n",
      "          [-2.5864e-08,  2.2352e-08, -2.2590e-08,  2.3329e-08, -1.5716e-08],\n",
      "          [-5.1571e-09,  2.1533e-10, -6.0797e-09,  6.4124e-09, -8.6246e-09],\n",
      "          [-1.0964e-08,  1.3364e-08, -1.1377e-08,  1.6193e-08, -1.1078e-08],\n",
      "          [-1.6492e-08,  4.9248e-09,  2.8461e-09, -3.9597e-10, -8.6869e-09]],\n",
      "\n",
      "         [[ 6.6163e-09,  4.5391e-09,  1.0719e-08,  4.1556e-09,  2.0501e-08],\n",
      "          [-1.0262e-08, -4.8163e-09, -2.0660e-08,  1.3145e-09, -1.1629e-08],\n",
      "          [ 1.3370e-09,  2.9324e-09,  8.1540e-09,  2.3519e-09,  1.7366e-08],\n",
      "          [-3.5297e-10, -3.9132e-09,  2.9697e-09, -1.4152e-08, -4.7642e-09],\n",
      "          [ 3.0020e-08,  1.4681e-09,  1.5604e-08,  5.1355e-09,  3.8892e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1688e-10,  1.7999e-09, -1.1908e-09,  2.1430e-09, -3.0937e-10],\n",
      "          [-1.3650e-09,  5.3586e-11, -1.3120e-09,  7.1048e-11,  3.3897e-10],\n",
      "          [-1.4689e-09,  2.3707e-09, -4.7958e-10,  1.8590e-09, -3.0658e-10],\n",
      "          [-3.5311e-10, -1.1162e-10, -2.7440e-09, -3.1329e-10, -1.4103e-09],\n",
      "          [ 2.7901e-10,  1.0437e-09,  6.0972e-10,  1.3641e-09, -2.2550e-10]],\n",
      "\n",
      "         [[-3.2131e-08,  3.6164e-08, -5.5936e-08,  1.2001e-08, -2.6912e-08],\n",
      "          [-2.5018e-08,  2.4670e-08, -3.4264e-08,  3.8408e-09, -6.8820e-09],\n",
      "          [-6.0112e-08,  6.0144e-08, -4.5872e-08,  5.9650e-08, -3.8681e-08],\n",
      "          [-1.1119e-08,  1.8052e-08, -9.9634e-09,  3.2155e-08,  2.9422e-10],\n",
      "          [-2.1063e-08,  2.9327e-08, -4.6692e-08,  2.6250e-08, -3.1203e-08]],\n",
      "\n",
      "         [[ 8.8877e-09, -6.5596e-09,  8.0694e-09, -6.9369e-09,  1.0786e-08],\n",
      "          [-1.6308e-09, -1.0693e-10,  7.2666e-10,  1.5468e-09, -1.0945e-09],\n",
      "          [ 4.5697e-09, -3.4371e-09,  6.5170e-09, -1.3476e-09,  3.7732e-09],\n",
      "          [-3.7541e-09, -5.6959e-10, -1.1991e-09, -8.9444e-10,  9.1032e-10],\n",
      "          [ 8.9568e-09, -2.3760e-09,  5.1742e-09, -7.6386e-09,  8.0584e-09]]],\n",
      "\n",
      "\n",
      "        [[[-2.2873e-09,  2.9534e-09, -1.7455e-09,  1.5687e-09, -2.4903e-10],\n",
      "          [ 9.0823e-10, -6.2577e-09, -1.2996e-10, -4.6450e-09,  1.8233e-09],\n",
      "          [-1.2767e-09,  3.3553e-09,  1.1275e-09,  3.5916e-09, -7.0790e-10],\n",
      "          [ 4.9550e-11, -5.7510e-09,  1.1393e-09, -6.5971e-09,  2.8508e-10],\n",
      "          [ 5.1186e-10,  3.4011e-09, -1.2448e-10,  4.6394e-09,  2.1444e-09]],\n",
      "\n",
      "         [[-1.1914e-09,  8.4729e-09,  7.4950e-10, -3.9422e-09, -2.2080e-08],\n",
      "          [-2.9683e-08,  3.9675e-08, -4.3027e-08,  3.6454e-08, -4.0973e-08],\n",
      "          [-8.2515e-09, -7.1243e-09, -8.1745e-09,  1.3801e-08, -2.4898e-08],\n",
      "          [-1.8886e-08,  4.5273e-08, -3.3621e-08,  3.2084e-08, -3.3024e-08],\n",
      "          [-6.7983e-09,  1.1097e-08,  9.1328e-09, -4.4666e-10, -2.1274e-08]],\n",
      "\n",
      "         [[ 4.8346e-08,  6.2810e-09,  1.9206e-08,  8.4833e-09,  1.7323e-08],\n",
      "          [-3.3323e-08, -6.3116e-09, -1.5707e-08, -2.1454e-08, -1.3001e-08],\n",
      "          [ 3.4636e-08,  1.6241e-08,  3.0223e-08,  5.5150e-09,  3.6639e-08],\n",
      "          [-7.9935e-09, -1.1472e-08, -2.6675e-08, -3.0394e-09, -6.9710e-09],\n",
      "          [ 4.8686e-08,  6.5788e-09,  4.0744e-08,  7.0468e-09,  5.0157e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0431e-09,  2.6407e-09, -4.7472e-10,  3.1656e-09, -8.1799e-10],\n",
      "          [-1.6264e-09, -8.9191e-10, -1.8278e-09,  1.1963e-10, -1.0489e-09],\n",
      "          [-1.3945e-09,  3.7338e-09, -2.3259e-09,  2.7937e-09, -3.9139e-10],\n",
      "          [-3.4723e-09, -2.9311e-10, -3.1696e-09, -3.4457e-10, -1.6853e-09],\n",
      "          [-2.4930e-09,  4.5651e-09, -1.3364e-09,  5.1106e-09,  5.5491e-10]],\n",
      "\n",
      "         [[-4.1961e-08,  7.0872e-08, -9.3058e-08,  8.3541e-08, -8.9506e-08],\n",
      "          [-2.1696e-08,  3.5388e-08, -4.2382e-08,  3.7708e-08, -3.2353e-08],\n",
      "          [-8.3044e-08,  8.1647e-08, -8.1611e-08,  6.5134e-08, -9.2105e-08],\n",
      "          [-2.7903e-08,  5.0595e-08, -4.3248e-08,  4.5079e-08, -2.6671e-08],\n",
      "          [-9.7327e-08,  5.6873e-08, -1.0354e-07,  7.6643e-08, -9.7093e-08]],\n",
      "\n",
      "         [[ 1.1056e-08, -1.1367e-08,  1.1428e-08, -6.8408e-09,  1.6730e-08],\n",
      "          [-5.5172e-09, -2.6831e-09,  7.4234e-11, -5.7874e-09, -6.0645e-09],\n",
      "          [ 1.9890e-08, -8.0953e-09,  9.6504e-09, -7.8921e-09,  2.0674e-08],\n",
      "          [-5.8420e-09, -1.1275e-09, -3.2562e-09, -7.9039e-10, -2.1669e-09],\n",
      "          [ 1.1363e-08, -7.8299e-09,  2.5454e-08, -3.2422e-09,  1.2794e-08]]]],\n",
      "       device='cuda:0')\n",
      "tensor([-8.1997e-08, -4.3330e-10,  1.8548e-07,  2.9233e-08, -2.0773e-09,\n",
      "         1.3801e-07,  2.8533e-08, -3.1431e-08, -3.0136e-08,  8.1287e-09,\n",
      "         1.7802e-08,  1.0225e-08, -1.2921e-07,  1.3826e-07,  2.0562e-07,\n",
      "        -3.1980e-08, -2.4581e-09, -3.7300e-08, -2.8312e-10,  8.0643e-09,\n",
      "         5.3641e-09, -6.4333e-09, -2.9679e-08,  6.5838e-08, -3.7968e-08,\n",
      "         5.0066e-08, -7.8178e-08,  6.9120e-08, -1.0865e-08, -2.8246e-08,\n",
      "        -7.9254e-08, -1.5531e-08, -5.0480e-09,  2.3230e-08,  5.8392e-08,\n",
      "        -5.0469e-08,  2.6310e-08, -7.9703e-08,  2.5673e-08, -8.4266e-08,\n",
      "         1.0916e-07,  2.5802e-08,  6.7126e-08, -4.4879e-08,  4.3642e-08,\n",
      "         1.4648e-09, -1.5568e-08,  5.5882e-08, -1.2796e-07,  2.7365e-08,\n",
      "         9.5972e-08, -1.0967e-08, -2.9157e-08,  1.1857e-08,  6.8514e-09,\n",
      "         4.9135e-08,  3.5062e-08,  3.9791e-10, -3.2637e-08, -2.4002e-08,\n",
      "         9.2416e-08, -9.5037e-08,  5.1292e-08,  2.3508e-08,  2.0110e-08,\n",
      "         2.7677e-08,  4.8323e-09, -2.7046e-08, -3.3439e-08,  8.4101e-08,\n",
      "        -4.1251e-08, -3.6228e-09, -2.5013e-08, -7.4562e-08, -7.5626e-09,\n",
      "        -3.7293e-08, -1.9338e-08,  4.9301e-08,  9.6576e-09, -8.8222e-09,\n",
      "        -2.3421e-08,  1.1035e-08,  6.1356e-08,  5.9470e-08, -5.1434e-09,\n",
      "        -6.9857e-10,  1.3236e-07,  5.7629e-09,  2.4473e-08,  1.3673e-07,\n",
      "        -4.8375e-08, -7.6741e-08, -2.2077e-08, -4.6148e-08, -5.0082e-08,\n",
      "        -9.0417e-09, -4.9769e-08,  2.3947e-08, -2.8459e-08, -2.6920e-08,\n",
      "         4.1842e-08, -2.9693e-08,  1.0540e-07,  4.0274e-08,  3.3682e-08,\n",
      "        -1.3695e-08,  2.2307e-08,  4.8728e-08, -1.2648e-07,  6.2594e-08,\n",
      "         4.3484e-08, -3.3309e-08,  5.3704e-08, -3.5139e-09,  1.2792e-07,\n",
      "         4.5068e-08,  6.5699e-08, -6.2602e-08, -2.6545e-08, -9.5382e-09,\n",
      "         6.5597e-09, -1.0336e-07, -4.0565e-08,  6.9146e-08,  9.4374e-08,\n",
      "        -2.9885e-09, -4.8217e-08,  5.9300e-08], device='cuda:0')\n",
      "tensor([-8.6473e-08, -1.7010e-08,  1.7868e-07,  2.6686e-08, -6.0255e-09,\n",
      "         1.0503e-07,  3.0318e-08, -3.0455e-08, -4.9044e-08,  3.7721e-08,\n",
      "         1.5415e-09, -2.4279e-08, -8.8972e-08,  1.2132e-07,  1.5718e-07,\n",
      "        -2.0916e-08, -4.7569e-08, -2.5853e-08, -2.2875e-08,  4.6725e-09,\n",
      "        -7.6561e-09, -5.6032e-09, -2.3467e-08,  7.1340e-08, -9.9213e-09,\n",
      "         3.6772e-08, -7.4315e-08,  4.8901e-08, -1.6802e-08, -8.2058e-08,\n",
      "        -2.8112e-08, -1.9814e-08, -2.7608e-08,  1.2907e-08,  6.5861e-08,\n",
      "        -2.3257e-08,  3.5518e-08, -7.3397e-08,  2.2579e-08, -8.7483e-08,\n",
      "         1.1176e-07,  2.1816e-08,  4.8910e-08, -4.7156e-08,  1.8583e-08,\n",
      "        -9.8572e-09, -9.4743e-09,  3.5726e-08, -8.0287e-08,  2.5813e-08,\n",
      "         7.7140e-08, -2.4087e-08, -2.7404e-08,  2.6032e-09,  1.6445e-09,\n",
      "         2.4627e-08,  3.1139e-08, -5.1736e-08, -1.7937e-08, -3.5702e-08,\n",
      "         5.8292e-08, -1.4523e-07,  3.2106e-08,  3.0259e-08, -1.9684e-08,\n",
      "         1.6626e-09,  1.4485e-08, -2.7072e-08, -5.5879e-08,  7.0589e-08,\n",
      "        -3.4115e-08, -3.7989e-09, -7.5249e-09, -7.6472e-08, -2.7659e-08,\n",
      "        -2.7670e-08, -2.2507e-08,  5.1612e-08,  2.9179e-08, -2.7352e-08,\n",
      "        -4.7599e-08, -1.5787e-08,  4.7564e-08,  3.7175e-08, -3.6709e-09,\n",
      "        -1.9078e-08,  3.1337e-08, -1.0836e-08,  1.0871e-08,  1.1072e-07,\n",
      "        -7.5372e-08, -7.4743e-08, -2.7436e-08, -5.5854e-08, -2.2379e-08,\n",
      "         2.1076e-08, -6.2374e-08, -1.9978e-09, -2.8150e-08, -1.4097e-08,\n",
      "         5.5794e-08, -2.6321e-08,  9.6572e-08,  3.4485e-08,  2.2058e-08,\n",
      "        -4.1622e-08,  2.9569e-08,  7.4877e-09, -1.0512e-07,  7.4159e-08,\n",
      "         3.9539e-08, -3.2152e-08,  5.6778e-08,  7.8134e-09,  6.5408e-08,\n",
      "         6.0227e-08,  5.6238e-08, -5.9141e-08, -2.9754e-08, -1.3890e-08,\n",
      "         6.8941e-09, -1.5164e-07, -5.9063e-08,  6.0794e-08,  9.1295e-08,\n",
      "        -6.4154e-09, -1.3866e-08,  2.9784e-08], device='cuda:0')\n",
      "tensor([-1.4141e-06,  2.4598e-06,  2.5085e-06], device='cuda:0')\n",
      "tensor([[[[-4.9612e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.3854e-09]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5110e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 7.4333e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.0214e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5000e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3822e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.8982e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.4212e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7335e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6881e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7070e-08]]],\n",
      "\n",
      "\n",
      "        [[[-4.3511e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4144e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9366e-06]]],\n",
      "\n",
      "\n",
      "        [[[-9.5740e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.8039e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.9624e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.8621e-09]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5018e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0754e-08]]],\n",
      "\n",
      "\n",
      "        [[[-3.6755e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.8469e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3849e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.2941e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6079e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.4612e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3872e-07]]],\n",
      "\n",
      "\n",
      "        [[[-8.4283e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.4440e-07]]],\n",
      "\n",
      "\n",
      "        [[[-4.2447e-07]]],\n",
      "\n",
      "\n",
      "        [[[-5.5383e-08]]],\n",
      "\n",
      "\n",
      "        [[[-7.1612e-09]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2022e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1419e-07]]],\n",
      "\n",
      "\n",
      "        [[[-4.3610e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1960e-07]]],\n",
      "\n",
      "\n",
      "        [[[-5.6127e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4829e-08]]],\n",
      "\n",
      "\n",
      "        [[[-5.0570e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5950e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6265e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3693e-07]]],\n",
      "\n",
      "\n",
      "        [[[-5.4476e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9308e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7776e-08]]],\n",
      "\n",
      "\n",
      "        [[[-7.3825e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8741e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.3367e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6640e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9250e-07]]],\n",
      "\n",
      "\n",
      "        [[[-6.3822e-09]]],\n",
      "\n",
      "\n",
      "        [[[-1.6289e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2649e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6659e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2417e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4634e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0601e-09]]],\n",
      "\n",
      "\n",
      "        [[[-3.2573e-07]]],\n",
      "\n",
      "\n",
      "        [[[-9.2145e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2156e-07]]],\n",
      "\n",
      "\n",
      "        [[[-7.0972e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4814e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9831e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1558e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3859e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6695e-08]]],\n",
      "\n",
      "\n",
      "        [[[-1.1473e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.4735e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3117e-07]]],\n",
      "\n",
      "\n",
      "        [[[-4.4629e-08]]],\n",
      "\n",
      "\n",
      "        [[[-3.6698e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.0470e-07]]],\n",
      "\n",
      "\n",
      "        [[[-7.3308e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.8586e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.3775e-07]]],\n",
      "\n",
      "\n",
      "        [[[-5.0788e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5538e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5992e-08]]],\n",
      "\n",
      "\n",
      "        [[[-5.7063e-08]]],\n",
      "\n",
      "\n",
      "        [[[-9.5154e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8583e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1361e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0693e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.5163e-08]]],\n",
      "\n",
      "\n",
      "        [[[-8.3486e-10]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1501e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1189e-09]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3735e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9283e-07]]],\n",
      "\n",
      "\n",
      "        [[[-3.2347e-07]]],\n",
      "\n",
      "\n",
      "        [[[-6.4624e-08]]],\n",
      "\n",
      "\n",
      "        [[[-9.3998e-09]]],\n",
      "\n",
      "\n",
      "        [[[-3.9556e-07]]],\n",
      "\n",
      "\n",
      "        [[[-3.2033e-07]]],\n",
      "\n",
      "\n",
      "        [[[-8.3897e-08]]],\n",
      "\n",
      "\n",
      "        [[[-1.9655e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8577e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.5893e-07]]],\n",
      "\n",
      "\n",
      "        [[[-3.1226e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2859e-07]]],\n",
      "\n",
      "\n",
      "        [[[-5.1589e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4733e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6666e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6248e-08]]],\n",
      "\n",
      "\n",
      "        [[[-7.8577e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1003e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0502e-07]]],\n",
      "\n",
      "\n",
      "        [[[-4.7687e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0284e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6468e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.7988e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9857e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.6969e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2743e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8163e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3318e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.5844e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.9820e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.5113e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4057e-08]]],\n",
      "\n",
      "\n",
      "        [[[-9.3495e-07]]],\n",
      "\n",
      "\n",
      "        [[[-3.8156e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4565e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 7.4871e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.0228e-09]]],\n",
      "\n",
      "\n",
      "        [[[-3.7779e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3237e-07]]]], device='cuda:0')\n",
      "tensor([[[[-5.3296e-08,  3.2203e-08, -1.0441e-08, -4.8917e-08, -2.9670e-08],\n",
      "          [ 2.6041e-08, -2.0563e-08,  1.9059e-08, -8.1784e-09,  1.3073e-08],\n",
      "          [-4.0005e-08,  1.4656e-08,  5.1637e-09, -1.7849e-08, -5.2533e-08],\n",
      "          [-7.8018e-09,  1.3552e-09, -3.3695e-08, -1.7046e-08,  1.0422e-08],\n",
      "          [-5.5165e-08,  1.1503e-08, -5.5950e-09, -1.1271e-08, -3.5168e-08]],\n",
      "\n",
      "         [[ 1.7989e-08, -2.9995e-08,  4.9410e-08,  3.8597e-08,  3.1565e-08],\n",
      "          [-2.2294e-08,  4.7222e-08, -5.6474e-09,  1.3751e-08, -1.0636e-08],\n",
      "          [ 2.6341e-08, -2.5895e-08,  3.3869e-08,  4.5079e-08,  2.1461e-09],\n",
      "          [-1.7166e-08,  5.5995e-08, -1.7264e-08,  1.9798e-08, -6.6326e-09],\n",
      "          [ 3.4989e-08, -5.4550e-09,  4.6192e-08,  3.9842e-08,  2.1646e-08]],\n",
      "\n",
      "         [[-1.5712e-08, -7.6162e-10, -4.9584e-08,  6.2580e-08,  1.0375e-08],\n",
      "          [ 2.5452e-08,  3.1320e-08,  5.1066e-08, -4.3582e-09,  3.8604e-08],\n",
      "          [-5.8129e-09,  1.4298e-10, -1.5971e-08,  4.2094e-08, -9.9834e-09],\n",
      "          [ 2.4524e-08,  2.5027e-08,  5.6763e-08, -3.2211e-08,  1.4517e-08],\n",
      "          [-1.0542e-08, -1.0766e-08, -4.3424e-08,  3.5917e-08,  2.0059e-10]]],\n",
      "\n",
      "\n",
      "        [[[-2.2418e-07, -8.5636e-08, -5.8260e-08,  3.0115e-08, -3.4721e-07],\n",
      "          [ 3.4876e-07, -1.1769e-07, -7.3150e-09, -1.1584e-07,  1.5997e-07],\n",
      "          [-1.5123e-07,  1.5805e-07, -3.2131e-07, -2.3825e-07, -1.8697e-07],\n",
      "          [-1.2634e-07,  4.3999e-08,  2.8186e-07, -3.5681e-07, -4.7659e-08],\n",
      "          [-2.6756e-07, -2.0633e-08,  7.9923e-09,  1.8389e-07, -4.1939e-07]],\n",
      "\n",
      "         [[-1.0356e-07, -2.2640e-07,  4.4823e-07,  3.5457e-07, -2.1325e-07],\n",
      "          [-6.2246e-08,  2.3888e-07, -1.3746e-07,  4.0665e-07,  4.7061e-08],\n",
      "          [ 7.5725e-07,  2.1359e-07,  5.7140e-08, -8.2241e-08,  6.0105e-07],\n",
      "          [-1.1789e-07,  2.5717e-07, -2.4868e-07,  1.4301e-07, -1.3827e-07],\n",
      "          [-2.6690e-07, -5.7003e-09,  5.1548e-07,  3.5654e-07, -2.5895e-07]],\n",
      "\n",
      "         [[-2.5126e-07,  1.5335e-07, -1.7999e-07,  3.6837e-07, -2.5103e-08],\n",
      "          [ 2.7131e-07,  1.5318e-07,  3.4576e-07,  3.1593e-07,  2.1576e-07],\n",
      "          [-1.8774e-07,  2.7833e-07, -2.0975e-07,  7.0739e-08, -2.1735e-07],\n",
      "          [ 2.9518e-07,  2.1698e-07,  2.9428e-07, -3.2272e-07,  2.3145e-07],\n",
      "          [-2.5124e-07,  1.5440e-07, -9.2262e-08,  2.8660e-07, -9.1738e-08]]],\n",
      "\n",
      "\n",
      "        [[[-1.0067e-06,  1.5551e-07,  9.8101e-08, -2.1795e-07, -1.2924e-06],\n",
      "          [ 4.1149e-07, -1.5504e-07, -1.9247e-07, -3.7464e-07,  4.5186e-07],\n",
      "          [-8.6915e-07,  4.7655e-07,  4.3691e-07, -7.6027e-07, -5.4826e-07],\n",
      "          [ 1.2603e-07, -4.5544e-08, -2.0169e-07, -2.6561e-07, -2.1872e-07],\n",
      "          [-1.0997e-06,  2.5368e-07,  5.5353e-07,  6.7934e-08, -9.6387e-07]],\n",
      "\n",
      "         [[ 1.0566e-07, -1.1651e-06,  8.2039e-07,  4.7191e-07,  2.5717e-08],\n",
      "          [ 3.3918e-08,  1.8846e-07, -2.9476e-07,  3.8932e-07, -3.7415e-07],\n",
      "          [ 4.1542e-08, -2.0676e-07, -3.6066e-07,  9.9548e-07, -2.4264e-08],\n",
      "          [ 7.0667e-09,  9.9879e-07, -1.4921e-07,  1.0696e-07,  3.0902e-07],\n",
      "          [ 3.5339e-07, -8.5611e-07,  1.0869e-06,  5.4861e-07,  3.8439e-07]],\n",
      "\n",
      "         [[-1.8682e-08, -4.7175e-07, -9.6550e-07,  1.2315e-06,  2.3772e-07],\n",
      "          [ 1.6290e-08,  2.6801e-07,  5.1070e-07,  8.1669e-08,  2.7275e-07],\n",
      "          [ 3.7350e-07, -3.0836e-07, -3.5439e-07,  8.3259e-07,  2.0307e-08],\n",
      "          [ 1.9384e-07,  9.6788e-07,  9.6087e-07,  3.0400e-07,  5.2663e-07],\n",
      "          [-5.9574e-08, -4.8412e-07, -7.7534e-07,  9.6559e-07,  2.2639e-07]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.2385e-08,  1.7681e-08, -8.3999e-09, -2.4069e-08, -3.7476e-08],\n",
      "          [-6.2321e-10, -8.9679e-09,  2.6442e-08, -2.4176e-08, -1.0838e-08],\n",
      "          [-4.9473e-08, -6.4675e-09, -4.4374e-10, -9.5599e-09, -4.4761e-08],\n",
      "          [ 1.7371e-08,  3.0742e-09, -2.6009e-08, -1.7128e-08,  1.8506e-08],\n",
      "          [-5.1354e-08,  6.5148e-09, -1.3752e-08, -2.5709e-08, -5.6080e-08]],\n",
      "\n",
      "         [[ 6.8912e-08, -6.1992e-09,  9.4687e-09,  1.0733e-08,  6.2231e-08],\n",
      "          [-6.5126e-09,  4.5061e-08, -2.2688e-08,  1.2929e-08,  4.7994e-09],\n",
      "          [-3.6494e-08, -2.3339e-08,  7.7996e-08,  5.5626e-08, -2.6768e-08],\n",
      "          [ 4.6307e-09,  2.9664e-08, -1.4029e-08,  5.1074e-08, -1.1240e-08],\n",
      "          [ 6.5386e-08,  1.0863e-08,  2.2820e-10,  3.5425e-09,  6.3089e-08]],\n",
      "\n",
      "         [[-1.2673e-08,  1.7741e-08, -4.4290e-08,  3.9485e-08, -1.2689e-08],\n",
      "          [ 1.4023e-08,  6.0431e-08,  2.6481e-08, -3.8865e-09,  3.5137e-08],\n",
      "          [-2.6885e-09, -3.1533e-09, -2.3264e-08,  4.4772e-08, -1.7204e-08],\n",
      "          [ 4.0873e-08,  1.7225e-08,  4.1840e-08,  2.1984e-08,  4.4313e-08],\n",
      "          [-1.1747e-08,  1.3887e-08, -2.8404e-08,  4.5295e-08, -2.6354e-08]]],\n",
      "\n",
      "\n",
      "        [[[-8.5967e-07,  7.7863e-08, -5.5757e-07, -2.0129e-09, -8.2579e-07],\n",
      "          [ 3.1885e-07, -2.2825e-07,  2.0725e-08, -3.8863e-07,  2.0539e-07],\n",
      "          [-8.0106e-08, -5.9596e-08,  5.1938e-08, -3.6538e-07, -1.9885e-07],\n",
      "          [ 1.5424e-07,  1.3561e-07, -4.1485e-08,  2.2488e-07, -1.3716e-07],\n",
      "          [-9.7651e-07,  1.9831e-07, -2.7835e-07, -1.7723e-07, -7.0052e-07]],\n",
      "\n",
      "         [[ 1.0482e-06, -6.8555e-07,  1.1254e-06, -1.3677e-07,  6.3011e-07],\n",
      "          [-4.4853e-07,  4.9694e-08, -3.3521e-07, -2.5177e-08, -3.4731e-07],\n",
      "          [-1.0473e-07,  3.1831e-07, -5.3905e-07,  7.2794e-07, -4.8117e-07],\n",
      "          [ 9.5214e-08,  1.1307e-06, -1.7278e-08,  9.9903e-07,  1.2831e-07],\n",
      "          [ 1.1632e-06, -5.8001e-07,  1.1787e-06, -6.3704e-08,  8.9587e-07]],\n",
      "\n",
      "         [[-4.6429e-07,  2.4854e-07, -7.5800e-07,  6.4138e-07, -3.2879e-07],\n",
      "          [ 2.6110e-07,  6.6503e-08,  6.2903e-07,  6.0495e-08,  5.3198e-08],\n",
      "          [ 1.4120e-07,  6.5411e-08, -9.4324e-08,  2.3086e-07,  1.4394e-07],\n",
      "          [ 7.4249e-07,  6.1413e-07,  8.1556e-07,  3.2233e-07,  6.0913e-07],\n",
      "          [-5.6330e-07,  3.1036e-07, -4.9445e-07,  5.4543e-07, -3.5532e-07]]],\n",
      "\n",
      "\n",
      "        [[[-3.1788e-07,  4.0227e-08,  1.3636e-08, -9.9165e-08, -3.1914e-07],\n",
      "          [ 8.6002e-08, -3.9814e-08, -9.3008e-08, -1.7218e-07,  9.2492e-08],\n",
      "          [-9.6019e-08,  1.0815e-07,  7.1475e-08, -1.3580e-07, -1.5260e-07],\n",
      "          [-1.2584e-08, -4.1936e-08, -4.9847e-09,  7.9921e-08, -1.8164e-08],\n",
      "          [-2.4009e-07,  5.7949e-08,  7.5994e-09, -1.5437e-07, -2.9585e-07]],\n",
      "\n",
      "         [[ 1.6972e-07, -2.0642e-07,  3.7703e-07,  1.5128e-07,  8.3613e-08],\n",
      "          [-5.5774e-08,  8.1017e-08, -2.0868e-07,  5.1638e-09, -5.9083e-08],\n",
      "          [-3.0002e-08,  8.5198e-08, -7.1232e-08,  2.8953e-07, -4.6988e-08],\n",
      "          [ 3.7285e-08,  3.2530e-07, -4.6935e-08,  1.9215e-07, -1.0585e-08],\n",
      "          [ 1.6655e-07, -2.0682e-07,  3.9522e-07,  1.3304e-07,  1.6986e-07]],\n",
      "\n",
      "         [[-8.7648e-08, -3.8893e-08, -2.4196e-07,  2.3447e-07, -5.8544e-08],\n",
      "          [ 7.0931e-08,  1.9741e-08,  1.8248e-07, -1.1483e-07,  8.6982e-08],\n",
      "          [-1.9129e-08,  2.9549e-08, -1.1433e-07,  1.5595e-07,  6.5109e-08],\n",
      "          [ 1.2161e-07,  3.0356e-07,  2.5881e-07, -5.3739e-08,  1.6450e-07],\n",
      "          [-5.2031e-08, -3.6280e-08, -2.0191e-07,  2.3238e-07,  1.9243e-08]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Start Training\n",
    "'''\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_accuracy = 0\n",
    "    G_loss = 0\n",
    "    D_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        img, label, label_onehot, label_mask = data\n",
    "        label_mask = label_mask.float()\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            label_onehot = label_onehot.cuda()\n",
    "            label_mask = label_mask.cuda()\n",
    "\n",
    "#         for j, im in enumerate(img):\n",
    "#             if torch.sum(im) == 0:\n",
    "#                 no = (batch_size * i) + j\n",
    "#                 print(no, label[j])\n",
    "#                 if label[j] not in substance_list:\n",
    "#                     substance_list.append(label[j])\n",
    "#                 im = im.detach().cpu().numpy()\n",
    "#                 im = Image.fromarray(im)\n",
    "#                 im.save('tcga_check/' + str(i) + '_' + str(j) + '.jpg', format='JPEG')\n",
    "        \n",
    "        b_size = img.size(0)\n",
    "        \n",
    "        ################### Discriminator ####################\n",
    "        batch_d_loss = 0\n",
    "        batch_accuracy = 0\n",
    "        \n",
    "        for d_i in range(discriminator_frequency):\n",
    "            d_loss, d_accuracy = train_discriminator(optimizer_D, b_size, img, label, label_mask, epsilon)\n",
    "            batch_d_loss += d_loss.item()  \n",
    "            batch_accuracy += d_accuracy\n",
    "            \n",
    "        batch_d_loss = batch_d_loss/float(discriminator_frequency)\n",
    "        batch_accuracy = batch_accuracy/float(discriminator_frequency)\n",
    "        \n",
    "        ################### Generator ####################\n",
    "        batch_g_loss = 0\n",
    "        for g_i in range(generator_frequency):\n",
    "            g_loss, fake_img = train_generator(optimizer_G, b_size, epsilon)\n",
    "            batch_g_loss += g_loss.item()\n",
    "        batch_g_loss = batch_g_loss/float(generator_frequency)\n",
    "       \n",
    "        total_accuracy += batch_accuracy\n",
    "        D_loss += batch_d_loss\n",
    "        G_loss += batch_g_loss\n",
    "        \n",
    "        # Save best model\n",
    "        save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': discriminator.state_dict(),\n",
    "        'optimizer' : optimizer_D.state_dict(),\n",
    "        }, 'dis')\n",
    "        save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': generator.state_dict(),\n",
    "        'optimizer' : optimizer_G.state_dict(),\n",
    "        }, 'gen')\n",
    "        \n",
    "        if i%b_size == b_size-1:\n",
    "            print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\" % (epoch, num_epochs, i, \n",
    "                                       len(train_loader), d_loss.item(), 100 * batch_accuracy, g_loss.item()))\n",
    "\n",
    "        \n",
    "    # Print Epoch results\n",
    "    total_accuracy = total_accuracy/float(i+1)\n",
    "    avg_D_loss = D_loss/float(i+1)\n",
    "    avg_G_loss = G_loss/float(i+1)\n",
    "    \n",
    "    print('--------------------------------------------------------------------')\n",
    "    print(\"===> [Epoch %d/%d] [Avg D loss: %f, avg acc: %d%%] [Avg G loss: %f]\" % (epoch, num_epochs, \n",
    "                                                        avg_D_loss, 100 * total_accuracy, avg_G_loss))\n",
    "    print('--------------------------------------------------------------------')\n",
    "    \n",
    "    # Save Images\n",
    "    save_image(fake_img[:25], image_dir + '/epoch_%d_batch_%d.png' % (epoch, i), nrow=5, normalize=True)\n",
    "    \n",
    "    # Tensorboard logging \n",
    "    \n",
    "    # 1. Log scalar values (scalar summary)\n",
    "    info = { 'Epoch': epoch, 'G_loss': avg_G_loss, 'D_loss': avg_D_loss, 'accuracy': total_accuracy }\n",
    "    for tag, value in info.items():\n",
    "        logger.scalar_summary(tag, value, epoch)\n",
    "    \n",
    "    # 2. Log values and gradients of the parameters (histogram summary)\n",
    "    # Generator summary\n",
    "    for tag, value in generator.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        logger.histo_summary(tag, value.detach().cpu().numpy(), epoch)\n",
    "        logger.histo_summary(tag+'/grad', value.grad.detach().cpu().numpy(), epoch)\n",
    "    \n",
    "    #Discriminator summary\n",
    "    for tag, value in discriminator.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        logger.histo_summary(tag, value.detach().cpu().numpy(), epoch)\n",
    "        logger.histo_summary(tag+'/grad', value.grad.detach().cpu().numpy(), epoch)\n",
    "        \n",
    "    # 3. Log generated images (image summary)\n",
    "    info = { image_dir : fake_img.view(-1, image_size, image_size)[:10].detach().cpu().numpy() }\n",
    "\n",
    "    for tag, images in info.items():\n",
    "        logger.image_summary(tag, images, epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
