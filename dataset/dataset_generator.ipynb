{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import matplotlib.path as mpltPath\n",
    "from matplotlib.path import Path\n",
    "from random import shuffle\n",
    "from openslide import open_slide, ImageSlide\n",
    "import scipy.io as sio\n",
    "import pdb\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File paths\n",
    "slide_path = '/mys3bucket/TCGA_LUSC'\n",
    "slides = os.listdir(slide_path)\n",
    "save_path = '/home/ubuntu/codebase/Semi-Supervised-GANs/dataset/patch_data'\n",
    "\n",
    "no_patches = 500\n",
    "no_train_slides = 200\n",
    "no_dev_slides = 100\n",
    "no_test_slides = 100\n",
    "chunk_size = 20\n",
    "\n",
    "def split(data):\n",
    "    N = len(data)\n",
    "    trn_idx = int(np.ceil(0.7*N))\n",
    "    dev_idx = int(np.ceil(0.2*(N)))\n",
    "    \n",
    "    train = data[:trn_idx]\n",
    "    dev = data[trn_idx:trn_idx+dev_idx]\n",
    "    test = data[trn_idx+dev_idx:]\n",
    "    \n",
    "    return train,dev,test\n",
    "\n",
    "\n",
    "def get_mask(coords):\n",
    "    coords.sort(key=lambda x: x[0],reverse=True)\n",
    "    xmin,xmax = coords[-1][0],coords[0][0]\n",
    "    coords.sort(key=lambda x: x[1],reverse=True)\n",
    "    ymin,ymax = coords[-1][1],coords[0][1]\n",
    "    maximum = max(xmax,ymax)\n",
    "    minimum = min(xmin,ymin)\n",
    "    x, y = np.meshgrid(np.arange(minimum,maximum), np.arange(minimum,maximum))\n",
    "    print(\"Done generating meshgrid!\")\n",
    "    x, y = x.flatten(), y.flatten()\n",
    "    points = np.vstack((x,y)).T\n",
    "    p = Path(coords)\n",
    "    grid = p.contains_points(points)\n",
    "    mask = grid.reshape((maximum-minimum),(maximum-minimum))\n",
    "    mask = mask.astype(int)\n",
    "    x_coords,y_coords = np.nonzero(mask)\n",
    "    sample_idxs = np.random.choice(x_coords, no_patches)\n",
    "    return x[sample_idxs],y[sample_idxs]\n",
    "    \n",
    "def read_patches(x_coords,y_coords,slide_src,label):\n",
    "    gen_dataX = []\n",
    "    gen_dataY = []\n",
    "    image = open_slide(slide_src)\n",
    "    for i in range(len(x_coords)):\n",
    "        patch = image.read_region((x_coords[i],y_coords[i]),0,(256,256))\n",
    "        patch = patch.convert(\"RGB\")\n",
    "        patch = np.array(patch)\n",
    "        gen_dataX.append(patch)\n",
    "        gen_dataY.append(label)\n",
    "        \n",
    "        #Code to save patches as images\n",
    "        #outfile = os.path.join(slide_dest,\"patch_\"+str(i)+\".jpg\")\n",
    "        #patch.save(outfile,'JPEG')\n",
    "        #g.write((\"patch_\"+str(count)+\",\"+str(x_coords[i])+\",\"+str(y_coords[i])+\"\\n\"))\n",
    "        \n",
    "    image.close()\n",
    "    print(\"Generated patches!\")\n",
    "    return gen_dataX,gen_dataY\n",
    "\n",
    "def get_slide_path(slideID):\n",
    "    for slide in slides:\n",
    "        if str(slideID) == str(slide.split('_')[0]):\n",
    "            return os.path.join(slide_path,slide)\n",
    "    return -1\n",
    "\n",
    "def get_random_polygon(shape):\n",
    "    if len(shape)>1:\n",
    "        return shape\n",
    "    return -1\n",
    "\n",
    "def generate_data(data, slide_threshold,mode):\n",
    "    \n",
    "    DATAX = []\n",
    "    DATAY = []\n",
    "    count = 0\n",
    "    start = 0\n",
    "    chunk_no = 1\n",
    "    for annotation in data:\n",
    "        slide = annotation['slideId']\n",
    "        shape = annotation['shape']\n",
    "        label = annotation['annotationSubstanceId']\n",
    "        polygon = get_random_polygon(shape)\n",
    "        slide_src = get_slide_path(slide)\n",
    "        \n",
    "        if slide_src == -1:\n",
    "            print(str(slide)+\" file does not exist\")\n",
    "            sys.stdout.flush()\n",
    "            continue\n",
    "        if polygon == -1:\n",
    "            print(str(slide)+\" has only point annotation\")\n",
    "            sys.stdout.flush()\n",
    "            continue\n",
    "\n",
    "        coords = [tuple(x) for x in polygon]\n",
    "        x_coords,y_coords = get_mask(coords)\n",
    "        X,Y = read_patches(x_coords,y_coords,slide_src,label)\n",
    "        DATAX.extend(X)\n",
    "        DATAY.extend(Y)\n",
    "        count+=1\n",
    "        print(\">>>>\"+str(count))\n",
    "        \n",
    "        #Saving chunks of data containing slide_threshold*no_patches\n",
    "        if count%chunk_size==0 :\n",
    "            save_dataX = DATAX[start:start+(slide_threshold*no_patches)]\n",
    "            save_dataY = DATAY[start:start+(slide_threshold*no_patches)]\n",
    "            start += (slide_threshold*no_patches)\n",
    "            outfile = os.path.join(save_path,mode,str(chunk_no))\n",
    "            np.savez(outfile,np.asarray(save_dataX),np.asarray(save_dataY))\n",
    "            chunk_no+=1\n",
    "            \n",
    "        if count == slide_threshold: # Getting patches only for threshold number of slides\n",
    "            break\n",
    "        print(\"*****************************************************\")\n",
    "        \n",
    "    return np.asarray(DATAX),np.asarray(DATAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the data\n",
    "f = open(\"/mys3bucket/Annotations/annotations.txt\", encoding=\"utf-8\")\n",
    "data = json.loads(f.read())\n",
    "f.close()\n",
    "\n",
    "\n",
    "#shuffle(data)\n",
    "train,dev,test = split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = generate_data(train, no_train_slides,'train')\n",
    "print(\"Train data generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devX, devY = generate_data(dev, no_dev_slides,'dev')\n",
    "print(\"Dev data generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = generate_data(test, no_test_slides,'test')\n",
    "print(\"Test data generated! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to numpy files\n",
    "train_outfile = \"train.npy\"\n",
    "dev_outfile = \"dev.npy\"\n",
    "test_outfile = \"test.npy\"\n",
    "\n",
    "np.save(train_outfile,train_dataset)\n",
    "np.save(dev_outfile,dev_dataset)\n",
    "np.save(test_outfile,test_dataset)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
